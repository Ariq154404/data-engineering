\documentclass{resume}

\begin{document}

\section*{Ariq Rahman}
\begin{tabular}{lr}
  Mobile: 4373660580 & Address: 3 Calumet Crescent, M1H 1W4 \\
\end{tabular}

\section*{Education}
\textbf{Master of Applied Computing, Artificial Intelligence Stream} \\
University of Windsor, Windsor, Ontario (May 2022 - August 2023)

\textbf{Bachelor of Science in Computer Science and Engineering} \\
Islamic University of Technology, Dhaka, Bangladesh (January 2016 - November 2019)

\section*{Work Experience}

\textbf{Data Analytics Intern, TD Bank of Canada} (April - August 2023) \\
- Developed a Python Selenium script to automate ServiceNow queries and download files for ETL processes. \\
- Created dashboards in PowerBI using optimized PowerQuery for ETL process.

\textbf{Artificial Intelligence Engineer, Intelligent Machines} (Sept 2021 - April 2022) \\
- Worked on a handwritten text recognition project for Unilever Bangladesh. \\
- Performed data analysis, data visualization, and feature engineering on over 700 GB of image data using Python libraries such as Numpy, Pandas, and Matplotlib in an Azure Databricks cluster. \\
- Deployed a deep learning model as Docker TensorFlow Serving for batch analysis.

\section*{Personal Projects}

\subsection*{MLops on AWS}
Developed a Machine Learning Operations (MLOps) pipeline on AWS using SageMaker. Utilized a Kaggle dataset containing tweets about climate change and performed data preprocessing, label encoding, and tokenization with the Roberta model. The data was stored in AWS feature stores for training and testing. Technologies used include AWS SageMaker, Python libraries such as \textbf{sklearn}, \textbf{multiprocessing}, \textbf{transformer}, \textbf{numpy}, \textbf{pandas}, \textbf{tensorflow}, \textbf{argparse}, and \textbf{boto3}.

\subsection*{A/B Testing on Questionnaire Dataset}
Conducted A/B testing on a survey dataset, evaluating responses to product purchases from control and exposed groups. Calculated the p-value for the A/B testing using Python libraries like \textbf{numpy}, \textbf{pandas}, \textbf{scipy}, \textbf{seaborn}, \textbf{matplotlib}, \textbf{math}, and \textbf{statsmodel}.

\subsection*{AWS Orchestration of Bitcoin Forecast}
Orchestrated multiple notebooks to forecast Bitcoin prices using AWS Event Bridge. Each stage of the pipeline (preprocessing, training, evaluation) triggered the next stage via AWS SageMaker. The notebooks were executed from AWS Lambda functions, utilizing \textbf{boto3}, \textbf{sagemaker}, \textbf{pickle}, \textbf{matplotlib}, and \textbf{pandas} libraries.

\subsection*{Data Engineering with Large Language Model (LLM)}
Automated tailoring of resumes using a large language model (LLM). Created an ETL DAG using Apache Airflow to extract job descriptions, filter out keywords using LLM, and store the extracted keywords in a Cassandra data model. Another DAG retrieved job with keyword skills and churned tailored resumes.

\section*{Certifications}
\textbf{TensorFlow Developer Certification} \\
\textbf{Azure Associate Data Scientist (DP-100) Certification}

\end{document}Link to apply job :https://ca.linkedin.com/jobs/view/python-developer-data-engineer-at-nearsource-technologies-3727395149