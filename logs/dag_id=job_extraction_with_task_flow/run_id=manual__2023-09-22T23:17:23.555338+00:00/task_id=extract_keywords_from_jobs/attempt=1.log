[2023-09-22T23:17:33.122+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: job_extraction_with_task_flow.extract_keywords_from_jobs manual__2023-09-22T23:17:23.555338+00:00 [queued]>
[2023-09-22T23:17:33.128+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: job_extraction_with_task_flow.extract_keywords_from_jobs manual__2023-09-22T23:17:23.555338+00:00 [queued]>
[2023-09-22T23:17:33.129+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2023-09-22T23:17:33.137+0000] {taskinstance.py:1350} INFO - Executing <Task(_PythonDecoratedOperator): extract_keywords_from_jobs> on 2023-09-22 23:17:23.555338+00:00
[2023-09-22T23:17:33.142+0000] {standard_task_runner.py:57} INFO - Started process 423 to run task
[2023-09-22T23:17:33.145+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'job_extraction_with_task_flow', 'extract_keywords_from_jobs', 'manual__2023-09-22T23:17:23.555338+00:00', '--job-id', '3', '--raw', '--subdir', 'DAGS_FOLDER/test3.py', '--cfg-path', '/tmp/tmp0l9bnnwd']
[2023-09-22T23:17:33.148+0000] {standard_task_runner.py:85} INFO - Job 3: Subtask extract_keywords_from_jobs
[2023-09-22T23:17:33.160+0000] {logging_mixin.py:149} WARNING - /home/***/.local/lib/python3.9/site-packages/***/settings.py:188 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-09-22T23:17:33.187+0000] {task_command.py:410} INFO - Running <TaskInstance: job_extraction_with_task_flow.extract_keywords_from_jobs manual__2023-09-22T23:17:23.555338+00:00 [running]> on host b03915951e77
[2023-09-22T23:17:33.245+0000] {taskinstance.py:1568} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='job_extraction_with_task_flow' AIRFLOW_CTX_TASK_ID='extract_keywords_from_jobs' AIRFLOW_CTX_EXECUTION_DATE='2023-09-22T23:17:23.555338+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-09-22T23:17:23.555338+00:00'
[2023-09-22T23:17:33.588+0000] {util.py:67} INFO - error_code=context_length_exceeded error_message="This model's maximum context length is 4097 tokens. However, you requested 4131 tokens (1082 in the messages, 49 in the functions, and 3000 in the completion). Please reduce the length of the messages, functions, or completion." error_param=messages error_type=invalid_request_error message='OpenAI API error received' stream_error=False
[2023-09-22T23:17:33.590+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/decorators/base.py", line 220, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/test3.py", line 108, in extract_keywords_from_jobs
    result.append(job)
UnboundLocalError: local variable 'result' referenced before assignment
[2023-09-22T23:17:33.609+0000] {taskinstance.py:1368} INFO - Marking task as FAILED. dag_id=job_extraction_with_task_flow, task_id=extract_keywords_from_jobs, execution_date=20230922T231723, start_date=20230922T231733, end_date=20230922T231733
[2023-09-22T23:17:33.636+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 3 for task extract_keywords_from_jobs (local variable 'result' referenced before assignment; 423)
[2023-09-22T23:17:33.678+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2023-09-22T23:17:33.714+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
