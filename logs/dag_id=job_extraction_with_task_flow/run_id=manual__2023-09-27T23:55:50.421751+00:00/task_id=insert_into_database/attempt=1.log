[2023-09-27T23:58:58.539+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: job_extraction_with_task_flow.insert_into_database manual__2023-09-27T23:55:50.421751+00:00 [queued]>
[2023-09-27T23:58:58.545+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: job_extraction_with_task_flow.insert_into_database manual__2023-09-27T23:55:50.421751+00:00 [queued]>
[2023-09-27T23:58:58.546+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2023-09-27T23:58:58.553+0000] {taskinstance.py:1350} INFO - Executing <Task(_PythonDecoratedOperator): insert_into_database> on 2023-09-27 23:55:50.421751+00:00
[2023-09-27T23:58:58.557+0000] {standard_task_runner.py:57} INFO - Started process 412 to run task
[2023-09-27T23:58:58.560+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'job_extraction_with_task_flow', 'insert_into_database', 'manual__2023-09-27T23:55:50.421751+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/ETL.py', '--cfg-path', '/tmp/tmp5fok4ino']
[2023-09-27T23:58:58.565+0000] {standard_task_runner.py:85} INFO - Job 4: Subtask insert_into_database
[2023-09-27T23:58:58.577+0000] {logging_mixin.py:149} WARNING - /home/***/.local/lib/python3.9/site-packages/***/settings.py:188 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-09-27T23:58:58.603+0000] {task_command.py:410} INFO - Running <TaskInstance: job_extraction_with_task_flow.insert_into_database manual__2023-09-27T23:55:50.421751+00:00 [running]> on host 06e87816369c
[2023-09-27T23:58:58.662+0000] {taskinstance.py:1568} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='job_extraction_with_task_flow' AIRFLOW_CTX_TASK_ID='insert_into_database' AIRFLOW_CTX_EXECUTION_DATE='2023-09-27T23:55:50.421751+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-09-27T23:55:50.421751+00:00'
[2023-09-27T23:58:58.664+0000] {logging_mixin.py:149} INFO - Results [{'employer_name': 'Workafy', 'job_employment_type': 'FULLTIME', 'job_title': 'Full time / Data Analyst (Remote)', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/full-time-data-analyst-remote-at-workafy-3727521438', 'job_description': 'The Data Analyst is a passionate, outgoing, responsible, and experienced professional who ensures a complete and robust data system and maintains data policies and procedures on an ongoing basis. General responsibilities include management of policy and procedure information, data system development and maintenance, program evaluation, data analysis, quality management and reporting.\n\nThis position requires critical thinking and analysis through a race equity lens, as well as demonstration of compassion, understanding and empathy while working with diverse staff, guests and community partners in a multi-racial and multi-cultural environment.\n\nKey Responsibilities\n• Devise and implement efficient and secure procedures for data collection, handling, processing and analysis\n• Develop and administer surveys, focus groups and other tools to elevate client voice\n• Develop, document and disseminate data policies and procedures and ensure that updates are incorporated to keep materials accurate and current\n• Identify data errors, coding errors or other issues which impact data quality and resolve and implement strategies to improve data quality, reliability and efficiency\n• Train and coach data system users on processes and procedures to support the proper daily use of data systems and ensure adherence to established standards; provide technical assistance as requested\n• Maintain internal database and assist with the ongoing development of a complete internal data system including the development, construction, testing and maintenance of architectures that are aligned with program requirements\n• Collaborate across multiple departments to improve data processes and meet programmatic/organizational needs\n• Collect and process data for analysis and conduct regular analysis to identify trends and areas for quality improvement\n• Create/maintain dashboards, visualizations, queries, reports and reporting tools and share results across multiple levels of the organization and externally to demonstrate impact and facilitate decision-making\n• Respond to data requests and provide accurate and appropriate interpretation of data\n• Lead data-driven conversations with program and executive teams\n• Manage external data partnerships and provide requested data to external partners as needed\n• Participate in regular staff and team meetings\n• Ensure all responsibilities are carried out and adhere to all rules and policies\n• Maintain ongoing and open communication with Data and Analytics Manager and Director of Community Impact as well as other leadership staff and support staff\n• Embrace the mission of centering equity and opportunity for women and families so no child sleeps outside and adhere to staff guidelines as outlined in the Employee Handbook\n• Maintain a calm demeanor and model positive behavior\n• Perform other duties as assigned\n\nSkills/Qualifications Required\n• Highly organized and attentive to detail\n• Ability to work as a part of a team and independently manage tasks\n• Experience working with people experiencing homelessness preferred\n• Bachelor’s degree or equivalent experience\n• 1+ years of experience as a data analyst or in a related field\n• Demonstrated experience in handling large data sets\n• Strong knowledge of and experience with databases and programming languages including SQL, Java, C++\n• Strong analytical skills with the ability to collect, organize, analyze and disseminate significant amounts of information with attention to detail and accuracy\n• Experience developing qualitative data processes and using qualitative analytical tools\n• Experience with program evaluation including statistical analysis software and advanced statistical analysis techniques\n• Working knowledge of office equipment, computer hardware and peripheral devices\n\nPowered by Webbtree', 'job_posted_at_timestamp': 1695805295, 'job_posted_at_datetime_utc': '2023-09-27T09:01:35.000Z', 'tag': 'ds', 'skills': ['critical thinking', 'analysis', 'compassion', 'empathy', 'data collection', 'data handling', 'data processing', 'data analysis', 'data quality', 'data development', 'data maintenance', 'policy management', 'program evaluation', 'quality management', 'reporting', 'survey development', 'group facilitation', 'data error identification', 'error resolution', 'data refinement', 'user training', 'database maintenance', 'data architecture', 'data collaboration', 'data analysis', 'dashboard creation', 'data visualization', 'data reporting', 'data interpretation', 'data-driven decision-making', 'data partnership management: collaboration, integration.', 'communication', 'equity', 'opportunity', 'calm demeanor', 'positive behavior']}, {'employer_name': 'Workafy', 'job_employment_type': 'FULLTIME', 'job_title': 'Full time / Data Analyst (Remote)', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/full-time-data-analyst-remote-at-workafy-3727521438', 'job_description': 'The Data Analyst is a passionate, outgoing, responsible, and experienced professional who ensures a complete and robust data system and maintains data policies and procedures on an ongoing basis. General responsibilities include management of policy and procedure information, data system development and maintenance, program evaluation, data analysis, quality management and reporting.\n\nThis position requires critical thinking and analysis through a race equity lens, as well as demonstration of compassion, understanding and empathy while working with diverse staff, guests and community partners in a multi-racial and multi-cultural environment.\n\nKey Responsibilities\n• Devise and implement efficient and secure procedures for data collection, handling, processing and analysis\n• Develop and administer surveys, focus groups and other tools to elevate client voice\n• Develop, document and disseminate data policies and procedures and ensure that updates are incorporated to keep materials accurate and current\n• Identify data errors, coding errors or other issues which impact data quality and resolve and implement strategies to improve data quality, reliability and efficiency\n• Train and coach data system users on processes and procedures to support the proper daily use of data systems and ensure adherence to established standards; provide technical assistance as requested\n• Maintain internal database and assist with the ongoing development of a complete internal data system including the development, construction, testing and maintenance of architectures that are aligned with program requirements\n• Collaborate across multiple departments to improve data processes and meet programmatic/organizational needs\n• Collect and process data for analysis and conduct regular analysis to identify trends and areas for quality improvement\n• Create/maintain dashboards, visualizations, queries, reports and reporting tools and share results across multiple levels of the organization and externally to demonstrate impact and facilitate decision-making\n• Respond to data requests and provide accurate and appropriate interpretation of data\n• Lead data-driven conversations with program and executive teams\n• Manage external data partnerships and provide requested data to external partners as needed\n• Participate in regular staff and team meetings\n• Ensure all responsibilities are carried out and adhere to all rules and policies\n• Maintain ongoing and open communication with Data and Analytics Manager and Director of Community Impact as well as other leadership staff and support staff\n• Embrace the mission of centering equity and opportunity for women and families so no child sleeps outside and adhere to staff guidelines as outlined in the Employee Handbook\n• Maintain a calm demeanor and model positive behavior\n• Perform other duties as assigned\n\nSkills/Qualifications Required\n• Highly organized and attentive to detail\n• Ability to work as a part of a team and independently manage tasks\n• Experience working with people experiencing homelessness preferred\n• Bachelor’s degree or equivalent experience\n• 1+ years of experience as a data analyst or in a related field\n• Demonstrated experience in handling large data sets\n• Strong knowledge of and experience with databases and programming languages including SQL, Java, C++\n• Strong analytical skills with the ability to collect, organize, analyze and disseminate significant amounts of information with attention to detail and accuracy\n• Experience developing qualitative data processes and using qualitative analytical tools\n• Experience with program evaluation including statistical analysis software and advanced statistical analysis techniques\n• Working knowledge of office equipment, computer hardware and peripheral devices\n\nPowered by Webbtree', 'job_posted_at_timestamp': 1695805295, 'job_posted_at_datetime_utc': '2023-09-27T09:01:35.000Z', 'tag': 'ds', 'skills': ['critical thinking', 'analysis', 'compassion', 'empathy', 'data collection', 'data handling', 'data processing', 'data analysis', 'data quality', 'data development', 'data maintenance', 'policy management', 'program evaluation', 'quality management', 'reporting', 'survey development', 'group facilitation', 'data error identification', 'error resolution', 'data refinement', 'user training', 'database maintenance', 'data architecture', 'data collaboration', 'data analysis', 'dashboard creation', 'data visualization', 'data reporting', 'data interpretation', 'data-driven decision-making', 'data partnership management: collaboration, integration.', 'communication', 'equity', 'opportunity', 'calm demeanor', 'positive behavior']}, {'employer_name': 'LightBox', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/data-engineer-at-lightbox-3726215111', 'job_description': "About Us\n\nLightBox is on a mission to modernize the real estate industry. We provide commercial, geographical, spatial, and environmental building data on a single platform. Our definitive data and intuitive products are transforming the way organizations of all sizes solve problems.\n\nPosition Overview\n\nWe are currently looking for an innovative Data Engineer to join our LightBox data integration team. LightBox ingests thousands of datasets and processes billions of data elements from petascale amounts of data, served out through tens of billions of API transactions yearly. You will be working on a highly motivated team that is responsible for data modelling and data architecting to solve various use case scenarios. Must be self-directed and comfortable supporting the data needs of multiple teams and products. Including exciting work with highly scalable data ingestion pipelines while working in a team with extremely qualified and accomplished data and software engineers to build, enhance, and maintain our data platform that supports our best in class products.\n\nWhat you will do and achieve\n\nReporting to the Data Integration Manager, the duties and responsibilities of the Data Engineer include, but are not limited to:\n• Provide operational and technical expertise related to vector and raster GIS data products.\n• Responsible for producing data products and reference data for software products through GIS activities such as digital map production, database compilation, data conversion, and quality control.\n• Create data pipelines to prepare and maintain data to solve specific use cases.\n• Model and architect data to solve business problems.\n• Adhere to high-quality development principles while delivering solutions on-time and on-budget.\n• Analyze and resolve technical and application problems.\n• Migrate existing workflows to newer infrastructures.\n• Analyze use cases and propose solutions to meet business objectives.\n\nWho you are\n\nEducation\n• Bachelor's degree or certificate in GIS from a recognized Post-Secondary university or college.\n• Must have an excellent academic record with a good grounding in Data Engineering and GIS principles.\n• Familiar with Standards, concepts, practices, and procedures within the field of Computer Science is an asset.\n\nExperience\n• 2 to 5 years experience as a data engineer.\n\nKey Knowledge & Skills\n• Experience with Relational databases.\n• SQL language and Server experience, spatial preferably.\n• Strong GIS knowledge of fundamental processes and functionality.\n• Experience with ARCGIS or MapInfo Professional.\n• Microsoft Office (Access, Excel, Word, PowerPoint).\n\nCore Competencies\n• Excellent interpersonal, written and oral communication skills.\n• Strong problem solving ability and organizational skills.\n• Must be detail-oriented with multi-tasking abilities.\n• Ability to work under strict deadlines.\n• Keen interest in data engineering and a “tinkering” mindset.\n• Driven to continually learn about and incorporate new technologies.\n• Thrive in a self-driven environment.\n• Understanding and integrating human and machine workflows.\n• Data Lake & Warehouse Modeling.\n• Git code repository experience.\n\nOther Desirable Attributes\n• At least one modern programming language, preferably Python.\n\nLightBox's Diversity Commitment\n\nLightBox is fully committed to employing a diverse workforce and creating an inclusive work environment that embraces everyone’s unique contributions, experiences, and values. We believe in unity in diversity and offer a collaborative work environment that encourages creativity, initiative and professional growth and provides a competitive salary and benefits package. We are better together when we support, recognize, and embrace our differences.\n\nThis job description is a general listing of the required tasks and expectations of the position and in no way implies that the duties listed above are the employee’s only responsibilities. The employee is expected to perform other tasks, responsibilities and training as instructed by their supervisors. Duties and responsibilities may change at any time with or without notice.\n\nThis position may require additional hours outside of the standard work schedule including occasional holiday, evening and/or weekend hours in order to meet deadlines or to accommodate customers.\n\nLightBox and all its holding companies are an equal opportunity/affirmative action employer. It is the policy of the LightBox and its holding companies to prohibit discrimination of any type and to afford equal employment opportunities to employees and applicants, without regard to race, color, religion, sex, national origin, age, disability, or veteran status.\n\nNO TELEPHONE CALLS OR AGENCY SOLICITATION PLEASE.", 'job_posted_at_timestamp': 1695851552, 'job_posted_at_datetime_utc': '2023-09-27T21:52:32.000Z', 'tag': 'ds', 'skills': ['data engineer', 'gis', 'relational databases', 'sql', 'arcgis', 'mapinfo professional', 'microsoft office', 'python', 'data modeling', 'version control']}, {'employer_name': 'LightBox', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/data-engineer-at-lightbox-3726215111', 'job_description': "About Us\n\nLightBox is on a mission to modernize the real estate industry. We provide commercial, geographical, spatial, and environmental building data on a single platform. Our definitive data and intuitive products are transforming the way organizations of all sizes solve problems.\n\nPosition Overview\n\nWe are currently looking for an innovative Data Engineer to join our LightBox data integration team. LightBox ingests thousands of datasets and processes billions of data elements from petascale amounts of data, served out through tens of billions of API transactions yearly. You will be working on a highly motivated team that is responsible for data modelling and data architecting to solve various use case scenarios. Must be self-directed and comfortable supporting the data needs of multiple teams and products. Including exciting work with highly scalable data ingestion pipelines while working in a team with extremely qualified and accomplished data and software engineers to build, enhance, and maintain our data platform that supports our best in class products.\n\nWhat you will do and achieve\n\nReporting to the Data Integration Manager, the duties and responsibilities of the Data Engineer include, but are not limited to:\n• Provide operational and technical expertise related to vector and raster GIS data products.\n• Responsible for producing data products and reference data for software products through GIS activities such as digital map production, database compilation, data conversion, and quality control.\n• Create data pipelines to prepare and maintain data to solve specific use cases.\n• Model and architect data to solve business problems.\n• Adhere to high-quality development principles while delivering solutions on-time and on-budget.\n• Analyze and resolve technical and application problems.\n• Migrate existing workflows to newer infrastructures.\n• Analyze use cases and propose solutions to meet business objectives.\n\nWho you are\n\nEducation\n• Bachelor's degree or certificate in GIS from a recognized Post-Secondary university or college.\n• Must have an excellent academic record with a good grounding in Data Engineering and GIS principles.\n• Familiar with Standards, concepts, practices, and procedures within the field of Computer Science is an asset.\n\nExperience\n• 2 to 5 years experience as a data engineer.\n\nKey Knowledge & Skills\n• Experience with Relational databases.\n• SQL language and Server experience, spatial preferably.\n• Strong GIS knowledge of fundamental processes and functionality.\n• Experience with ARCGIS or MapInfo Professional.\n• Microsoft Office (Access, Excel, Word, PowerPoint).\n\nCore Competencies\n• Excellent interpersonal, written and oral communication skills.\n• Strong problem solving ability and organizational skills.\n• Must be detail-oriented with multi-tasking abilities.\n• Ability to work under strict deadlines.\n• Keen interest in data engineering and a “tinkering” mindset.\n• Driven to continually learn about and incorporate new technologies.\n• Thrive in a self-driven environment.\n• Understanding and integrating human and machine workflows.\n• Data Lake & Warehouse Modeling.\n• Git code repository experience.\n\nOther Desirable Attributes\n• At least one modern programming language, preferably Python.\n\nLightBox's Diversity Commitment\n\nLightBox is fully committed to employing a diverse workforce and creating an inclusive work environment that embraces everyone’s unique contributions, experiences, and values. We believe in unity in diversity and offer a collaborative work environment that encourages creativity, initiative and professional growth and provides a competitive salary and benefits package. We are better together when we support, recognize, and embrace our differences.\n\nThis job description is a general listing of the required tasks and expectations of the position and in no way implies that the duties listed above are the employee’s only responsibilities. The employee is expected to perform other tasks, responsibilities and training as instructed by their supervisors. Duties and responsibilities may change at any time with or without notice.\n\nThis position may require additional hours outside of the standard work schedule including occasional holiday, evening and/or weekend hours in order to meet deadlines or to accommodate customers.\n\nLightBox and all its holding companies are an equal opportunity/affirmative action employer. It is the policy of the LightBox and its holding companies to prohibit discrimination of any type and to afford equal employment opportunities to employees and applicants, without regard to race, color, religion, sex, national origin, age, disability, or veteran status.\n\nNO TELEPHONE CALLS OR AGENCY SOLICITATION PLEASE.", 'job_posted_at_timestamp': 1695851552, 'job_posted_at_datetime_utc': '2023-09-27T21:52:32.000Z', 'tag': 'ds', 'skills': ['data engineer', 'gis', 'relational databases', 'sql', 'arcgis', 'mapinfo professional', 'microsoft office', 'python', 'data modeling', 'version control']}, {'employer_name': 'Arista Networks', 'job_employment_type': 'FULLTIME', 'job_title': 'Software Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/software-engineer-at-arista-networks-3727903805', 'job_description': "Arista Networks is looking for world-class software engineers to join our Extensible Operating System (EOS) software development team.As a core member of the EOS team, you will be part of a fast-paced,high caliber team-building features to run the world's largest data center networks.Your software will be a key component of Arista's EOS, Arista's unique, Linux-based network operating system that runs on all of Arista's data center networking products.\n\nThe EOS team is responsible for all aspects of the development and delivery of software meant to run on the various Arista switches.You will work with your fellow engineers and members of the marketing team to gather and understand the functional and technical requirements for upcoming projects.You will help write functional specifications, design specifications, test plans, and the code to bring all of these to life.You will also work with customers to triage and fix problems in their networks. Internally, you will develop automated tests for your software, monitor the execution of those tests, and triage and fix problems found by your tests.At Arista, you will own your projects from definition to deployment, and you will be responsible for the quality of everything you deliver.\n\nThis role demands strong and broad software engineering fundamentals, and a good understanding of networking including capabilities like L2, L3, and fundamentals of commercial switching HW.Your role will not be limited to a single aspect of EOS at Arista, but cover all aspects of EOS.\n\nResponsibilities:\n• Write functional specifications and design specifications for features related to forwarding traffic on the internet and cloud data centers.\n• Independently implement solutions to small-sized problems in our EOS software, using the C, C++, and python programming languages.\n• Write test plan specifications for small-sized features in EOS, and implement automated test programs to execute the cases described in the test plan.\n• Debug problems found by our automated test programs and fix the problems.\n• Work on a team implementing, testing, and debugging solutions to larger routing protocol problems.\n• Worth with Customer Support Engineers to analyze problems in customer networks and provide fixes for those problems when needed in the form of new software releases or software patches.\n• Work with the System Test Engineers to analyze problems found in their tests and provide fixes for those problems.\n• Mentor new and junior engineers to bring them up to speed in Arista’s software development environment.\n• Review and contribute to the specifications and implementations written by other team members.\n• Help to create a schedule for the implementation and debugging tasks, update that schedule weekly, and report it to the project lead.\n\nQualifications\n• BSc, MS or Ph.D. in Computer Science/Electrical Engineering/Computer Engineering with 1+ years of related work experience\n• Knowledge of C, C++, and/or python.\n• Knowledge of UNIX or Linux.\n• Understanding of L2/L3 networking including at least one of the following areas is desirable:\n• IP routing protocols, such as RIP, OSPF, BGP, IS-IS, or PIM.\n• Layer 2 features such as 802.1d bridging, the 802.1d Spanning Tree Protocol, the 802.1ax Link Aggregation Control Protocol, the 802.1AB Link Layer Discovery Protocol, or RFC 1812 IP routing.\n• Ability to utilize, test, and debug packet forwarding engine and a hardware component’s vendor provided software libraries in your solutions.\n• Infrastructure functions related to distributed systems such as messaging, signalling, databases, and command line interface techniques.\n• Hands on experience in the design and development of ethernet bridging or routing related software or distributed systems software is desirable.\n• Hands on experience with enterprise or service provider class Ethernet switch/router system software development, or significant PhD level research in the area of network routing and packet forwarding.\n• Applied understanding of software engineering principles.\n• Strong problem solving and software troubleshooting skills.\n• Ability to design a solution to a small-sized problem, and implement that solution without outside help.Able to work on a small team solving a medium-sized problem with limited oversight.\n\nAdditional Information\n\nAll your information will be kept confidential according to EEO guidelines.", 'job_posted_at_timestamp': 1695835192, 'job_posted_at_datetime_utc': '2023-09-27T17:19:52.000Z', 'tag': 'se', 'skills': ['software fundamentals', 'networking', 'c programming', 'c++ proficiency', 'python proficiency', 'unix', 'linux', 'routing protocols', 'network switching', 'packet forwarding', 'distributed systems', 'ethernet bridging', 'routing software', 'software engineering', 'problem solving']}, {'employer_name': 'Arista Networks', 'job_employment_type': 'FULLTIME', 'job_title': 'Software Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/software-engineer-at-arista-networks-3727903805', 'job_description': "Arista Networks is looking for world-class software engineers to join our Extensible Operating System (EOS) software development team.As a core member of the EOS team, you will be part of a fast-paced,high caliber team-building features to run the world's largest data center networks.Your software will be a key component of Arista's EOS, Arista's unique, Linux-based network operating system that runs on all of Arista's data center networking products.\n\nThe EOS team is responsible for all aspects of the development and delivery of software meant to run on the various Arista switches.You will work with your fellow engineers and members of the marketing team to gather and understand the functional and technical requirements for upcoming projects.You will help write functional specifications, design specifications, test plans, and the code to bring all of these to life.You will also work with customers to triage and fix problems in their networks. Internally, you will develop automated tests for your software, monitor the execution of those tests, and triage and fix problems found by your tests.At Arista, you will own your projects from definition to deployment, and you will be responsible for the quality of everything you deliver.\n\nThis role demands strong and broad software engineering fundamentals, and a good understanding of networking including capabilities like L2, L3, and fundamentals of commercial switching HW.Your role will not be limited to a single aspect of EOS at Arista, but cover all aspects of EOS.\n\nResponsibilities:\n• Write functional specifications and design specifications for features related to forwarding traffic on the internet and cloud data centers.\n• Independently implement solutions to small-sized problems in our EOS software, using the C, C++, and python programming languages.\n• Write test plan specifications for small-sized features in EOS, and implement automated test programs to execute the cases described in the test plan.\n• Debug problems found by our automated test programs and fix the problems.\n• Work on a team implementing, testing, and debugging solutions to larger routing protocol problems.\n• Worth with Customer Support Engineers to analyze problems in customer networks and provide fixes for those problems when needed in the form of new software releases or software patches.\n• Work with the System Test Engineers to analyze problems found in their tests and provide fixes for those problems.\n• Mentor new and junior engineers to bring them up to speed in Arista’s software development environment.\n• Review and contribute to the specifications and implementations written by other team members.\n• Help to create a schedule for the implementation and debugging tasks, update that schedule weekly, and report it to the project lead.\n\nQualifications\n• BSc, MS or Ph.D. in Computer Science/Electrical Engineering/Computer Engineering with 1+ years of related work experience\n• Knowledge of C, C++, and/or python.\n• Knowledge of UNIX or Linux.\n• Understanding of L2/L3 networking including at least one of the following areas is desirable:\n• IP routing protocols, such as RIP, OSPF, BGP, IS-IS, or PIM.\n• Layer 2 features such as 802.1d bridging, the 802.1d Spanning Tree Protocol, the 802.1ax Link Aggregation Control Protocol, the 802.1AB Link Layer Discovery Protocol, or RFC 1812 IP routing.\n• Ability to utilize, test, and debug packet forwarding engine and a hardware component’s vendor provided software libraries in your solutions.\n• Infrastructure functions related to distributed systems such as messaging, signalling, databases, and command line interface techniques.\n• Hands on experience in the design and development of ethernet bridging or routing related software or distributed systems software is desirable.\n• Hands on experience with enterprise or service provider class Ethernet switch/router system software development, or significant PhD level research in the area of network routing and packet forwarding.\n• Applied understanding of software engineering principles.\n• Strong problem solving and software troubleshooting skills.\n• Ability to design a solution to a small-sized problem, and implement that solution without outside help.Able to work on a small team solving a medium-sized problem with limited oversight.\n\nAdditional Information\n\nAll your information will be kept confidential according to EEO guidelines.", 'job_posted_at_timestamp': 1695835192, 'job_posted_at_datetime_utc': '2023-09-27T17:19:52.000Z', 'tag': 'se', 'skills': ['software fundamentals', 'networking', 'c programming', 'c++ proficiency', 'python proficiency', 'unix', 'linux', 'routing protocols', 'network switching', 'packet forwarding', 'distributed systems', 'ethernet bridging', 'routing software', 'software engineering', 'problem solving']}, {'employer_name': 'Microsoft', 'job_employment_type': 'FULLTIME', 'job_title': 'Skype Software Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/skype-software-engineer-at-microsoft-3726213136', 'job_description': "Communications is the basis of human relationships and collaboration. The Skype Consumer Group is delivering solutions that shape the experiences of millions of people who interact using Skype every day to message, call and interact with their friends, families and loved ones. The Skype Consumer Group is the engineering, operations and business group comprised of the Skype Consumer clients across many operating systems and devices and the cloud based backend services that power those clients. This group serves consumers and business customers globally.\n\nOur solution is built using a mix of web technologies: JavaScript, HTML, CSS (Cascading Style Sheets) and native platform components. It relies on wide range of cloud-based services comprising our calling, media, chat, presence and other services infrastructure.\n\nResponsibilities\n• Design and deliver applications that are performant, reliable and secure for millions of users\n• Develop apps that are instrumented, in addition to using analytics and A/B testing to drive features\n• Advocate for Agile, frequent app releases and modern software development lifecycle\n• Partnering with backend services to develop APIs using REST\n• Opportunities to highlight your technical skills to directly help customers\n• Focus on direct impact on product engineering decisions based upon customer experience and data\n• Define requirements, using structured design & modeling techniques and code review practice\n\nQualifications\n\nRequired/Minimum Qualifications:\n• Bachelor's Degree in Computer Science or related technical field AND 2+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#\n• OR equivalent experience.\n\nPreferred Qualifications\n• Experience with object-oriented languages like Java, C++ or C#\n• You have deep experience with React and JavaScript/Typescript\n• Solid understanding of algorithms, data structures, and design patterns.\n• Proficient with React and Typescript, or with JavaScript and willing to learn TypeScript.\n• Ability to collaborate and model for others - you can explain your work, you can ask good questions, you listen to your peers and your customers, and you like to give and receive feedback\n• Experienced in defining requirements, using structured design & modeling techniques and code review practices\n• Great curiosity and willingness to question.\n• Dedicated to continuous learning, with a focus on implementing features end-to-end.\n\nMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.", 'job_posted_at_timestamp': 1695850786, 'job_posted_at_datetime_utc': '2023-09-27T21:39:46.000Z', 'tag': 'se', 'skills': ['web technologies', 'cloud-based services', 'api development', 'agile', 'software cycle', 'react', 'javascript', 'typescript', 'algorithms', 'data structures', 'design patterns', 'collaboration', 'requirements definition', 'code review', 'continuous learning']}, {'employer_name': 'Microsoft', 'job_employment_type': 'FULLTIME', 'job_title': 'Skype Software Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/skype-software-engineer-at-microsoft-3726213136', 'job_description': "Communications is the basis of human relationships and collaboration. The Skype Consumer Group is delivering solutions that shape the experiences of millions of people who interact using Skype every day to message, call and interact with their friends, families and loved ones. The Skype Consumer Group is the engineering, operations and business group comprised of the Skype Consumer clients across many operating systems and devices and the cloud based backend services that power those clients. This group serves consumers and business customers globally.\n\nOur solution is built using a mix of web technologies: JavaScript, HTML, CSS (Cascading Style Sheets) and native platform components. It relies on wide range of cloud-based services comprising our calling, media, chat, presence and other services infrastructure.\n\nResponsibilities\n• Design and deliver applications that are performant, reliable and secure for millions of users\n• Develop apps that are instrumented, in addition to using analytics and A/B testing to drive features\n• Advocate for Agile, frequent app releases and modern software development lifecycle\n• Partnering with backend services to develop APIs using REST\n• Opportunities to highlight your technical skills to directly help customers\n• Focus on direct impact on product engineering decisions based upon customer experience and data\n• Define requirements, using structured design & modeling techniques and code review practice\n\nQualifications\n\nRequired/Minimum Qualifications:\n• Bachelor's Degree in Computer Science or related technical field AND 2+ years technical engineering experience with coding in languages including, but not limited to, C, C++, C#\n• OR equivalent experience.\n\nPreferred Qualifications\n• Experience with object-oriented languages like Java, C++ or C#\n• You have deep experience with React and JavaScript/Typescript\n• Solid understanding of algorithms, data structures, and design patterns.\n• Proficient with React and Typescript, or with JavaScript and willing to learn TypeScript.\n• Ability to collaborate and model for others - you can explain your work, you can ask good questions, you listen to your peers and your customers, and you like to give and receive feedback\n• Experienced in defining requirements, using structured design & modeling techniques and code review practices\n• Great curiosity and willingness to question.\n• Dedicated to continuous learning, with a focus on implementing features end-to-end.\n\nMicrosoft is an equal opportunity employer. Consistent with applicable law, all qualified applicants will receive consideration for employment without regard to age, ancestry, citizenship, color, family or medical care leave, gender identity or expression, genetic information, immigration status, marital status, medical condition, national origin, physical or mental disability, political affiliation, protected veteran or military status, race, ethnicity, religion, sex (including pregnancy), sexual orientation, or any other characteristic protected by applicable local laws, regulations and ordinances. If you need assistance and/or a reasonable accommodation due to a disability during the application process, read more about requesting accommodations.", 'job_posted_at_timestamp': 1695850786, 'job_posted_at_datetime_utc': '2023-09-27T21:39:46.000Z', 'tag': 'se', 'skills': ['web technologies', 'cloud-based services', 'api development', 'agile', 'software cycle', 'react', 'javascript', 'typescript', 'algorithms', 'data structures', 'design patterns', 'collaboration', 'requirements definition', 'code review', 'continuous learning']}, {'employer_name': 'NEARSOURCE TECHNOLOGIES', 'job_employment_type': 'FULLTIME', 'job_title': 'Python Developer / Data Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/python-developer-data-engineer-at-nearsource-technologies-3727395149', 'job_description': 'Responsibilities\n• You will need a product-focused mindset. It is essential for you to understand business requirements and architect systems that will scale and extend to accommodate those needs\n• Break down complex problems, document technical solutions and sequence work to make fast, iterative improvements\n• Build and scale data infrastructure that powers batch and real-time data processing of billions of records\n• Automate cloud infrastructure, services, and observability\n• Develop CI/CD pipelines and testing automation\n• Interface with data engineers, data scientists, product managers and all data stakeholders to understand their needs and promote best practices\n\nMinimum Qualifications\n• 1-3 years of relevant industry experience in big data systems, data processing and SQL databases\n• 1+ years of coding experience in Spark dataframes, Spark SQL, PySpark\n• 2+ years of hands on programming skills, able to write modular, maintainable code, preferably Python & SQL\n• Good understanding of SQL, dimensional modeling, and analytical big data warehouses like Hive and Snowflake\n• Familiar with ETL workflow management tools like Airflow\n\nPreferred Qualifications\n• Experience with version control and CICD tools like Git and Jenkins CI\n• Experience in working and analysing data on notebook solutions like Jupyter, EMR Notebooks, Apache Zeppelin\n• Problem solver with excellent written and interpersonal skills; ability to make sound, complex decisions in a fast-paced, technical environment.\n• Bachelors degree in computer science, Engineering or related field, or equivalent training, fellowship, or work experience', 'job_posted_at_timestamp': 1695788956, 'job_posted_at_datetime_utc': '2023-09-27T04:29:16.000Z', 'tag': 'pd', 'skills': ['product-focused mindset', 'business comprehension', 'architect systems', 'expand systems', 'problem analysis', 'technical documentation', 'sequence work', 'data engineering', 'scale infrastructure', 'cloud automation', 'automate services', 'automate observability', 'pipeline development', 'testing automation', 'data collaboration', 'data collaboration', 'product liaison', 'data stakeholders', 'best promotion', 'industry expertise', 'data processing', 'data processing', 'sql databases', 'coding experience', 'spark dataframes', 'spark sql', 'pyspark', 'programming skills', 'modular code', 'maintainable code', 'python', 'sql', 'sql understanding', 'dimensional modeling', 'analytical warehouses', 'hive', 'snowflake', 'workflow tools', '***', 'version control', 'cicd tools', 'git', 'jenkins ci', 'data analysis', 'notebook solutions', 'jupyter', 'emr notebooks', 'apache zeppelin', 'problem solver', 'strong writing', 'interpersonal skills', 'fast-paced environment', 'technical environment', 'bachelors degree', 'computer science', 'engineering', 'related field', 'equivalent training', 'fellowship', 'work experience']}, {'employer_name': 'NEARSOURCE TECHNOLOGIES', 'job_employment_type': 'FULLTIME', 'job_title': 'Python Developer / Data Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/python-developer-data-engineer-at-nearsource-technologies-3727395149', 'job_description': 'Responsibilities\n• You will need a product-focused mindset. It is essential for you to understand business requirements and architect systems that will scale and extend to accommodate those needs\n• Break down complex problems, document technical solutions and sequence work to make fast, iterative improvements\n• Build and scale data infrastructure that powers batch and real-time data processing of billions of records\n• Automate cloud infrastructure, services, and observability\n• Develop CI/CD pipelines and testing automation\n• Interface with data engineers, data scientists, product managers and all data stakeholders to understand their needs and promote best practices\n\nMinimum Qualifications\n• 1-3 years of relevant industry experience in big data systems, data processing and SQL databases\n• 1+ years of coding experience in Spark dataframes, Spark SQL, PySpark\n• 2+ years of hands on programming skills, able to write modular, maintainable code, preferably Python & SQL\n• Good understanding of SQL, dimensional modeling, and analytical big data warehouses like Hive and Snowflake\n• Familiar with ETL workflow management tools like Airflow\n\nPreferred Qualifications\n• Experience with version control and CICD tools like Git and Jenkins CI\n• Experience in working and analysing data on notebook solutions like Jupyter, EMR Notebooks, Apache Zeppelin\n• Problem solver with excellent written and interpersonal skills; ability to make sound, complex decisions in a fast-paced, technical environment.\n• Bachelors degree in computer science, Engineering or related field, or equivalent training, fellowship, or work experience', 'job_posted_at_timestamp': 1695788956, 'job_posted_at_datetime_utc': '2023-09-27T04:29:16.000Z', 'tag': 'pd', 'skills': ['product-focused mindset', 'business comprehension', 'architect systems', 'expand systems', 'problem analysis', 'technical documentation', 'sequence work', 'data engineering', 'scale infrastructure', 'cloud automation', 'automate services', 'automate observability', 'pipeline development', 'testing automation', 'data collaboration', 'data collaboration', 'product liaison', 'data stakeholders', 'best promotion', 'industry expertise', 'data processing', 'data processing', 'sql databases', 'coding experience', 'spark dataframes', 'spark sql', 'pyspark', 'programming skills', 'modular code', 'maintainable code', 'python', 'sql', 'sql understanding', 'dimensional modeling', 'analytical warehouses', 'hive', 'snowflake', 'workflow tools', '***', 'version control', 'cicd tools', 'git', 'jenkins ci', 'data analysis', 'notebook solutions', 'jupyter', 'emr notebooks', 'apache zeppelin', 'problem solver', 'strong writing', 'interpersonal skills', 'fast-paced environment', 'technical environment', 'bachelors degree', 'computer science', 'engineering', 'related field', 'equivalent training', 'fellowship', 'work experience']}, {'employer_name': 'LightBox', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/data-engineer-at-lightbox-3726215111', 'job_description': "About Us\n\nLightBox is on a mission to modernize the real estate industry. We provide commercial, geographical, spatial, and environmental building data on a single platform. Our definitive data and intuitive products are transforming the way organizations of all sizes solve problems.\n\nPosition Overview\n\nWe are currently looking for an innovative Data Engineer to join our LightBox data integration team. LightBox ingests thousands of datasets and processes billions of data elements from petascale amounts of data, served out through tens of billions of API transactions yearly. You will be working on a highly motivated team that is responsible for data modelling and data architecting to solve various use case scenarios. Must be self-directed and comfortable supporting the data needs of multiple teams and products. Including exciting work with highly scalable data ingestion pipelines while working in a team with extremely qualified and accomplished data and software engineers to build, enhance, and maintain our data platform that supports our best in class products.\n\nWhat you will do and achieve\n\nReporting to the Data Integration Manager, the duties and responsibilities of the Data Engineer include, but are not limited to:\n• Provide operational and technical expertise related to vector and raster GIS data products.\n• Responsible for producing data products and reference data for software products through GIS activities such as digital map production, database compilation, data conversion, and quality control.\n• Create data pipelines to prepare and maintain data to solve specific use cases.\n• Model and architect data to solve business problems.\n• Adhere to high-quality development principles while delivering solutions on-time and on-budget.\n• Analyze and resolve technical and application problems.\n• Migrate existing workflows to newer infrastructures.\n• Analyze use cases and propose solutions to meet business objectives.\n\nWho you are\n\nEducation\n• Bachelor's degree or certificate in GIS from a recognized Post-Secondary university or college.\n• Must have an excellent academic record with a good grounding in Data Engineering and GIS principles.\n• Familiar with Standards, concepts, practices, and procedures within the field of Computer Science is an asset.\n\nExperience\n• 2 to 5 years experience as a data engineer.\n\nKey Knowledge & Skills\n• Experience with Relational databases.\n• SQL language and Server experience, spatial preferably.\n• Strong GIS knowledge of fundamental processes and functionality.\n• Experience with ARCGIS or MapInfo Professional.\n• Microsoft Office (Access, Excel, Word, PowerPoint).\n\nCore Competencies\n• Excellent interpersonal, written and oral communication skills.\n• Strong problem solving ability and organizational skills.\n• Must be detail-oriented with multi-tasking abilities.\n• Ability to work under strict deadlines.\n• Keen interest in data engineering and a “tinkering” mindset.\n• Driven to continually learn about and incorporate new technologies.\n• Thrive in a self-driven environment.\n• Understanding and integrating human and machine workflows.\n• Data Lake & Warehouse Modeling.\n• Git code repository experience.\n\nOther Desirable Attributes\n• At least one modern programming language, preferably Python.\n\nLightBox's Diversity Commitment\n\nLightBox is fully committed to employing a diverse workforce and creating an inclusive work environment that embraces everyone’s unique contributions, experiences, and values. We believe in unity in diversity and offer a collaborative work environment that encourages creativity, initiative and professional growth and provides a competitive salary and benefits package. We are better together when we support, recognize, and embrace our differences.\n\nThis job description is a general listing of the required tasks and expectations of the position and in no way implies that the duties listed above are the employee’s only responsibilities. The employee is expected to perform other tasks, responsibilities and training as instructed by their supervisors. Duties and responsibilities may change at any time with or without notice.\n\nThis position may require additional hours outside of the standard work schedule including occasional holiday, evening and/or weekend hours in order to meet deadlines or to accommodate customers.\n\nLightBox and all its holding companies are an equal opportunity/affirmative action employer. It is the policy of the LightBox and its holding companies to prohibit discrimination of any type and to afford equal employment opportunities to employees and applicants, without regard to race, color, religion, sex, national origin, age, disability, or veteran status.\n\nNO TELEPHONE CALLS OR AGENCY SOLICITATION PLEASE.", 'job_posted_at_timestamp': 1695851552, 'job_posted_at_datetime_utc': '2023-09-27T21:52:32.000Z', 'tag': 'de', 'skills': ['data engineer', 'gis', 'relational databases', 'sql', 'arcgis', 'mapinfo professional', 'microsoft office', 'python', 'data modeling', 'version control']}, {'employer_name': 'LightBox', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/data-engineer-at-lightbox-3726215111', 'job_description': "About Us\n\nLightBox is on a mission to modernize the real estate industry. We provide commercial, geographical, spatial, and environmental building data on a single platform. Our definitive data and intuitive products are transforming the way organizations of all sizes solve problems.\n\nPosition Overview\n\nWe are currently looking for an innovative Data Engineer to join our LightBox data integration team. LightBox ingests thousands of datasets and processes billions of data elements from petascale amounts of data, served out through tens of billions of API transactions yearly. You will be working on a highly motivated team that is responsible for data modelling and data architecting to solve various use case scenarios. Must be self-directed and comfortable supporting the data needs of multiple teams and products. Including exciting work with highly scalable data ingestion pipelines while working in a team with extremely qualified and accomplished data and software engineers to build, enhance, and maintain our data platform that supports our best in class products.\n\nWhat you will do and achieve\n\nReporting to the Data Integration Manager, the duties and responsibilities of the Data Engineer include, but are not limited to:\n• Provide operational and technical expertise related to vector and raster GIS data products.\n• Responsible for producing data products and reference data for software products through GIS activities such as digital map production, database compilation, data conversion, and quality control.\n• Create data pipelines to prepare and maintain data to solve specific use cases.\n• Model and architect data to solve business problems.\n• Adhere to high-quality development principles while delivering solutions on-time and on-budget.\n• Analyze and resolve technical and application problems.\n• Migrate existing workflows to newer infrastructures.\n• Analyze use cases and propose solutions to meet business objectives.\n\nWho you are\n\nEducation\n• Bachelor's degree or certificate in GIS from a recognized Post-Secondary university or college.\n• Must have an excellent academic record with a good grounding in Data Engineering and GIS principles.\n• Familiar with Standards, concepts, practices, and procedures within the field of Computer Science is an asset.\n\nExperience\n• 2 to 5 years experience as a data engineer.\n\nKey Knowledge & Skills\n• Experience with Relational databases.\n• SQL language and Server experience, spatial preferably.\n• Strong GIS knowledge of fundamental processes and functionality.\n• Experience with ARCGIS or MapInfo Professional.\n• Microsoft Office (Access, Excel, Word, PowerPoint).\n\nCore Competencies\n• Excellent interpersonal, written and oral communication skills.\n• Strong problem solving ability and organizational skills.\n• Must be detail-oriented with multi-tasking abilities.\n• Ability to work under strict deadlines.\n• Keen interest in data engineering and a “tinkering” mindset.\n• Driven to continually learn about and incorporate new technologies.\n• Thrive in a self-driven environment.\n• Understanding and integrating human and machine workflows.\n• Data Lake & Warehouse Modeling.\n• Git code repository experience.\n\nOther Desirable Attributes\n• At least one modern programming language, preferably Python.\n\nLightBox's Diversity Commitment\n\nLightBox is fully committed to employing a diverse workforce and creating an inclusive work environment that embraces everyone’s unique contributions, experiences, and values. We believe in unity in diversity and offer a collaborative work environment that encourages creativity, initiative and professional growth and provides a competitive salary and benefits package. We are better together when we support, recognize, and embrace our differences.\n\nThis job description is a general listing of the required tasks and expectations of the position and in no way implies that the duties listed above are the employee’s only responsibilities. The employee is expected to perform other tasks, responsibilities and training as instructed by their supervisors. Duties and responsibilities may change at any time with or without notice.\n\nThis position may require additional hours outside of the standard work schedule including occasional holiday, evening and/or weekend hours in order to meet deadlines or to accommodate customers.\n\nLightBox and all its holding companies are an equal opportunity/affirmative action employer. It is the policy of the LightBox and its holding companies to prohibit discrimination of any type and to afford equal employment opportunities to employees and applicants, without regard to race, color, religion, sex, national origin, age, disability, or veteran status.\n\nNO TELEPHONE CALLS OR AGENCY SOLICITATION PLEASE.", 'job_posted_at_timestamp': 1695851552, 'job_posted_at_datetime_utc': '2023-09-27T21:52:32.000Z', 'tag': 'de', 'skills': ['data engineer', 'gis', 'relational databases', 'sql', 'arcgis', 'mapinfo professional', 'microsoft office', 'python', 'data modeling', 'version control']}, {'employer_name': 'NEARSOURCE TECHNOLOGIES', 'job_employment_type': 'FULLTIME', 'job_title': 'Python Developer / Data Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/python-developer-data-engineer-at-nearsource-technologies-3727395149', 'job_description': 'Responsibilities\n• You will need a product-focused mindset. It is essential for you to understand business requirements and architect systems that will scale and extend to accommodate those needs\n• Break down complex problems, document technical solutions and sequence work to make fast, iterative improvements\n• Build and scale data infrastructure that powers batch and real-time data processing of billions of records\n• Automate cloud infrastructure, services, and observability\n• Develop CI/CD pipelines and testing automation\n• Interface with data engineers, data scientists, product managers and all data stakeholders to understand their needs and promote best practices\n\nMinimum Qualifications\n• 1-3 years of relevant industry experience in big data systems, data processing and SQL databases\n• 1+ years of coding experience in Spark dataframes, Spark SQL, PySpark\n• 2+ years of hands on programming skills, able to write modular, maintainable code, preferably Python & SQL\n• Good understanding of SQL, dimensional modeling, and analytical big data warehouses like Hive and Snowflake\n• Familiar with ETL workflow management tools like Airflow\n\nPreferred Qualifications\n• Experience with version control and CICD tools like Git and Jenkins CI\n• Experience in working and analysing data on notebook solutions like Jupyter, EMR Notebooks, Apache Zeppelin\n• Problem solver with excellent written and interpersonal skills; ability to make sound, complex decisions in a fast-paced, technical environment.\n• Bachelors degree in computer science, Engineering or related field, or equivalent training, fellowship, or work experience', 'job_posted_at_timestamp': 1695788956, 'job_posted_at_datetime_utc': '2023-09-27T04:29:16.000Z', 'tag': 'de', 'skills': ['product-focused mindset', 'business comprehension', 'architect systems', 'expand systems', 'problem analysis', 'technical documentation', 'sequence work', 'data engineering', 'scale infrastructure', 'cloud automation', 'automate services', 'automate observability', 'pipeline development', 'testing automation', 'data collaboration', 'data collaboration', 'product liaison', 'data stakeholders', 'best promotion', 'industry expertise', 'data processing', 'data processing', 'sql databases', 'coding experience', 'spark dataframes', 'spark sql', 'pyspark', 'programming skills', 'modular code', 'maintainable code', 'python', 'sql', 'sql understanding', 'dimensional modeling', 'analytical warehouses', 'hive', 'snowflake', 'workflow tools', '***', 'version control', 'cicd tools', 'git', 'jenkins ci', 'data analysis', 'notebook solutions', 'jupyter', 'emr notebooks', 'apache zeppelin', 'problem solver', 'strong writing', 'interpersonal skills', 'fast-paced environment', 'technical environment', 'bachelors degree', 'computer science', 'engineering', 'related field', 'equivalent training', 'fellowship', 'work experience']}, {'employer_name': 'NEARSOURCE TECHNOLOGIES', 'job_employment_type': 'FULLTIME', 'job_title': 'Python Developer / Data Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/python-developer-data-engineer-at-nearsource-technologies-3727395149', 'job_description': 'Responsibilities\n• You will need a product-focused mindset. It is essential for you to understand business requirements and architect systems that will scale and extend to accommodate those needs\n• Break down complex problems, document technical solutions and sequence work to make fast, iterative improvements\n• Build and scale data infrastructure that powers batch and real-time data processing of billions of records\n• Automate cloud infrastructure, services, and observability\n• Develop CI/CD pipelines and testing automation\n• Interface with data engineers, data scientists, product managers and all data stakeholders to understand their needs and promote best practices\n\nMinimum Qualifications\n• 1-3 years of relevant industry experience in big data systems, data processing and SQL databases\n• 1+ years of coding experience in Spark dataframes, Spark SQL, PySpark\n• 2+ years of hands on programming skills, able to write modular, maintainable code, preferably Python & SQL\n• Good understanding of SQL, dimensional modeling, and analytical big data warehouses like Hive and Snowflake\n• Familiar with ETL workflow management tools like Airflow\n\nPreferred Qualifications\n• Experience with version control and CICD tools like Git and Jenkins CI\n• Experience in working and analysing data on notebook solutions like Jupyter, EMR Notebooks, Apache Zeppelin\n• Problem solver with excellent written and interpersonal skills; ability to make sound, complex decisions in a fast-paced, technical environment.\n• Bachelors degree in computer science, Engineering or related field, or equivalent training, fellowship, or work experience', 'job_posted_at_timestamp': 1695788956, 'job_posted_at_datetime_utc': '2023-09-27T04:29:16.000Z', 'tag': 'de', 'skills': ['product-focused mindset', 'business comprehension', 'architect systems', 'expand systems', 'problem analysis', 'technical documentation', 'sequence work', 'data engineering', 'scale infrastructure', 'cloud automation', 'automate services', 'automate observability', 'pipeline development', 'testing automation', 'data collaboration', 'data collaboration', 'product liaison', 'data stakeholders', 'best promotion', 'industry expertise', 'data processing', 'data processing', 'sql databases', 'coding experience', 'spark dataframes', 'spark sql', 'pyspark', 'programming skills', 'modular code', 'maintainable code', 'python', 'sql', 'sql understanding', 'dimensional modeling', 'analytical warehouses', 'hive', 'snowflake', 'workflow tools', '***', 'version control', 'cicd tools', 'git', 'jenkins ci', 'data analysis', 'notebook solutions', 'jupyter', 'emr notebooks', 'apache zeppelin', 'problem solver', 'strong writing', 'interpersonal skills', 'fast-paced environment', 'technical environment', 'bachelors degree', 'computer science', 'engineering', 'related field', 'equivalent training', 'fellowship', 'work experience']}, {'employer_name': 'Workafy', 'job_employment_type': 'FULLTIME', 'job_title': 'Full time / Data Analyst (Remote)', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/full-time-data-analyst-remote-at-workafy-3727521438', 'job_description': 'The Data Analyst is a passionate, outgoing, responsible, and experienced professional who ensures a complete and robust data system and maintains data policies and procedures on an ongoing basis. General responsibilities include management of policy and procedure information, data system development and maintenance, program evaluation, data analysis, quality management and reporting.\n\nThis position requires critical thinking and analysis through a race equity lens, as well as demonstration of compassion, understanding and empathy while working with diverse staff, guests and community partners in a multi-racial and multi-cultural environment.\n\nKey Responsibilities\n• Devise and implement efficient and secure procedures for data collection, handling, processing and analysis\n• Develop and administer surveys, focus groups and other tools to elevate client voice\n• Develop, document and disseminate data policies and procedures and ensure that updates are incorporated to keep materials accurate and current\n• Identify data errors, coding errors or other issues which impact data quality and resolve and implement strategies to improve data quality, reliability and efficiency\n• Train and coach data system users on processes and procedures to support the proper daily use of data systems and ensure adherence to established standards; provide technical assistance as requested\n• Maintain internal database and assist with the ongoing development of a complete internal data system including the development, construction, testing and maintenance of architectures that are aligned with program requirements\n• Collaborate across multiple departments to improve data processes and meet programmatic/organizational needs\n• Collect and process data for analysis and conduct regular analysis to identify trends and areas for quality improvement\n• Create/maintain dashboards, visualizations, queries, reports and reporting tools and share results across multiple levels of the organization and externally to demonstrate impact and facilitate decision-making\n• Respond to data requests and provide accurate and appropriate interpretation of data\n• Lead data-driven conversations with program and executive teams\n• Manage external data partnerships and provide requested data to external partners as needed\n• Participate in regular staff and team meetings\n• Ensure all responsibilities are carried out and adhere to all rules and policies\n• Maintain ongoing and open communication with Data and Analytics Manager and Director of Community Impact as well as other leadership staff and support staff\n• Embrace the mission of centering equity and opportunity for women and families so no child sleeps outside and adhere to staff guidelines as outlined in the Employee Handbook\n• Maintain a calm demeanor and model positive behavior\n• Perform other duties as assigned\n\nSkills/Qualifications Required\n• Highly organized and attentive to detail\n• Ability to work as a part of a team and independently manage tasks\n• Experience working with people experiencing homelessness preferred\n• Bachelor’s degree or equivalent experience\n• 1+ years of experience as a data analyst or in a related field\n• Demonstrated experience in handling large data sets\n• Strong knowledge of and experience with databases and programming languages including SQL, Java, C++\n• Strong analytical skills with the ability to collect, organize, analyze and disseminate significant amounts of information with attention to detail and accuracy\n• Experience developing qualitative data processes and using qualitative analytical tools\n• Experience with program evaluation including statistical analysis software and advanced statistical analysis techniques\n• Working knowledge of office equipment, computer hardware and peripheral devices\n\nPowered by Webbtree', 'job_posted_at_timestamp': 1695805295, 'job_posted_at_datetime_utc': '2023-09-27T09:01:35.000Z', 'tag': 'da', 'skills': ['critical thinking', 'analysis', 'compassion', 'empathy', 'data collection', 'data handling', 'data processing', 'data analysis', 'data quality', 'data system', 'data policies', 'data procedures', 'data errors', 'data coding', 'data efficiency', 'data training', 'database maintenance', 'data architecture', 'data collaboration', 'data analysis', 'data visualization', 'data reporting', 'data interpretation', 'data-driven decision-making', 'data partnerships', 'communication', 'equity', 'opportunity', 'calm demeanor', 'positive behavior']}, {'employer_name': 'Workafy', 'job_employment_type': 'FULLTIME', 'job_title': 'Full time / Data Analyst (Remote)', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/full-time-data-analyst-remote-at-workafy-3727521438', 'job_description': 'The Data Analyst is a passionate, outgoing, responsible, and experienced professional who ensures a complete and robust data system and maintains data policies and procedures on an ongoing basis. General responsibilities include management of policy and procedure information, data system development and maintenance, program evaluation, data analysis, quality management and reporting.\n\nThis position requires critical thinking and analysis through a race equity lens, as well as demonstration of compassion, understanding and empathy while working with diverse staff, guests and community partners in a multi-racial and multi-cultural environment.\n\nKey Responsibilities\n• Devise and implement efficient and secure procedures for data collection, handling, processing and analysis\n• Develop and administer surveys, focus groups and other tools to elevate client voice\n• Develop, document and disseminate data policies and procedures and ensure that updates are incorporated to keep materials accurate and current\n• Identify data errors, coding errors or other issues which impact data quality and resolve and implement strategies to improve data quality, reliability and efficiency\n• Train and coach data system users on processes and procedures to support the proper daily use of data systems and ensure adherence to established standards; provide technical assistance as requested\n• Maintain internal database and assist with the ongoing development of a complete internal data system including the development, construction, testing and maintenance of architectures that are aligned with program requirements\n• Collaborate across multiple departments to improve data processes and meet programmatic/organizational needs\n• Collect and process data for analysis and conduct regular analysis to identify trends and areas for quality improvement\n• Create/maintain dashboards, visualizations, queries, reports and reporting tools and share results across multiple levels of the organization and externally to demonstrate impact and facilitate decision-making\n• Respond to data requests and provide accurate and appropriate interpretation of data\n• Lead data-driven conversations with program and executive teams\n• Manage external data partnerships and provide requested data to external partners as needed\n• Participate in regular staff and team meetings\n• Ensure all responsibilities are carried out and adhere to all rules and policies\n• Maintain ongoing and open communication with Data and Analytics Manager and Director of Community Impact as well as other leadership staff and support staff\n• Embrace the mission of centering equity and opportunity for women and families so no child sleeps outside and adhere to staff guidelines as outlined in the Employee Handbook\n• Maintain a calm demeanor and model positive behavior\n• Perform other duties as assigned\n\nSkills/Qualifications Required\n• Highly organized and attentive to detail\n• Ability to work as a part of a team and independently manage tasks\n• Experience working with people experiencing homelessness preferred\n• Bachelor’s degree or equivalent experience\n• 1+ years of experience as a data analyst or in a related field\n• Demonstrated experience in handling large data sets\n• Strong knowledge of and experience with databases and programming languages including SQL, Java, C++\n• Strong analytical skills with the ability to collect, organize, analyze and disseminate significant amounts of information with attention to detail and accuracy\n• Experience developing qualitative data processes and using qualitative analytical tools\n• Experience with program evaluation including statistical analysis software and advanced statistical analysis techniques\n• Working knowledge of office equipment, computer hardware and peripheral devices\n\nPowered by Webbtree', 'job_posted_at_timestamp': 1695805295, 'job_posted_at_datetime_utc': '2023-09-27T09:01:35.000Z', 'tag': 'da', 'skills': ['critical thinking', 'analysis', 'compassion', 'empathy', 'data collection', 'data handling', 'data processing', 'data analysis', 'data quality', 'data system', 'data policies', 'data procedures', 'data errors', 'data coding', 'data efficiency', 'data training', 'database maintenance', 'data architecture', 'data collaboration', 'data analysis', 'data visualization', 'data reporting', 'data interpretation', 'data-driven decision-making', 'data partnerships', 'communication', 'equity', 'opportunity', 'calm demeanor', 'positive behavior']}, {'employer_name': 'Electronic Arts', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Analyst', 'job_apply_link': 'https://ca.bebee.com/job/20230927-8e43cea3b358ec70d6ea796e3fd97ca1', 'job_description': "The Opportunity Ahead:\n\nThe QVS team is the team responsible to verify and assess the multi-dimensional quality in all the experiences that EA creates. We are a large team, centrally positioned within the wider EA Studios organization, and are responsible for many activities such as quality strategies, user experience research, quality engineering, amongst others.\n\nAs a Data Analyst in QVS you will play a key role in supporting the busines through data analysis and reporting with the goal of improving the efficiency and quality of business operations. You should be an independent, curious, and analytical individual who has a passion for diving into data to solve business problems. Your insights will contribute the way how we run the business, and influence the quality of our games. The perfect candidate for this role loves the opportunity to optimally solve a problem without necessarily being attached to a certain tool or tech.\n\nWhat a Data Analyst does at EA:\n• Understands the business needs and requirements of the partner team and refines them continuously.\n• Performs data analysis on a business process to provide an objective view on how the business operates.\n• Defines, evaluates, and monitors metrics that provide continuous feedback on the efficacy of the business.\n• Queries data, transforms and augments it to build reports and dashboards complete with user documentation.\n• Prepares detailed reports and presentations that help the internal partner identify key areas of opportunity and insight to drive future design and decision-making.\n• Capable of designing and developing statistical analysis models for hypothesis testing, prediction, or inference.\n\nOur Next Data Analyst needs:\n• A bachelor's degree in Business, Statistics, Mathematics, Economics, Data Science, Analytics, or a related field\n• 1-3 years of experience in an analytics role using data to help guide decisions in a consumer products-oriented industry (e.g. gaming, entertainment, e-commerce).\n• Excellent SQL querying skills.\n• Proficiency analyzing large datasets in a spreadsheet program and in programmatic analysis tools (e.g. Python, R).\n• Experience with data visualization applications (e.g. PowerBI, Tableau, Looker).\n• Experience in statistical modelling (e.g. regression, clustering, predictive modelling).\n\nSkills\n• Capable of working in a fast-paced environment and can adapt to various situations.\n• Skillful communicator who is not afraid to ask questions, brings new insights to light, and tell stories utilizing data.\n• Professionalism in working with clients and working in a larger team environment.\n• Can establish sense of urgency and prioritize effectively to manage multiple tasks.\n• High level of business acumen\n\nWe are a global team of creators, storytellers, technologists, experience originators, innovators and so much more. We believe amazing games and experiences start with teams as diverse as the players and communities we serve. At Electronic Arts, the only limit is your imagination.", 'job_posted_at_timestamp': 1695805677, 'job_posted_at_datetime_utc': '2023-09-27T09:07:57.000Z', 'tag': 'da', 'skills': ['database querying', 'data analysis', 'data visualization', 'statistical modelling']}, {'employer_name': 'Electronic Arts', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Analyst', 'job_apply_link': 'https://ca.bebee.com/job/20230927-8e43cea3b358ec70d6ea796e3fd97ca1', 'job_description': "The Opportunity Ahead:\n\nThe QVS team is the team responsible to verify and assess the multi-dimensional quality in all the experiences that EA creates. We are a large team, centrally positioned within the wider EA Studios organization, and are responsible for many activities such as quality strategies, user experience research, quality engineering, amongst others.\n\nAs a Data Analyst in QVS you will play a key role in supporting the busines through data analysis and reporting with the goal of improving the efficiency and quality of business operations. You should be an independent, curious, and analytical individual who has a passion for diving into data to solve business problems. Your insights will contribute the way how we run the business, and influence the quality of our games. The perfect candidate for this role loves the opportunity to optimally solve a problem without necessarily being attached to a certain tool or tech.\n\nWhat a Data Analyst does at EA:\n• Understands the business needs and requirements of the partner team and refines them continuously.\n• Performs data analysis on a business process to provide an objective view on how the business operates.\n• Defines, evaluates, and monitors metrics that provide continuous feedback on the efficacy of the business.\n• Queries data, transforms and augments it to build reports and dashboards complete with user documentation.\n• Prepares detailed reports and presentations that help the internal partner identify key areas of opportunity and insight to drive future design and decision-making.\n• Capable of designing and developing statistical analysis models for hypothesis testing, prediction, or inference.\n\nOur Next Data Analyst needs:\n• A bachelor's degree in Business, Statistics, Mathematics, Economics, Data Science, Analytics, or a related field\n• 1-3 years of experience in an analytics role using data to help guide decisions in a consumer products-oriented industry (e.g. gaming, entertainment, e-commerce).\n• Excellent SQL querying skills.\n• Proficiency analyzing large datasets in a spreadsheet program and in programmatic analysis tools (e.g. Python, R).\n• Experience with data visualization applications (e.g. PowerBI, Tableau, Looker).\n• Experience in statistical modelling (e.g. regression, clustering, predictive modelling).\n\nSkills\n• Capable of working in a fast-paced environment and can adapt to various situations.\n• Skillful communicator who is not afraid to ask questions, brings new insights to light, and tell stories utilizing data.\n• Professionalism in working with clients and working in a larger team environment.\n• Can establish sense of urgency and prioritize effectively to manage multiple tasks.\n• High level of business acumen\n\nWe are a global team of creators, storytellers, technologists, experience originators, innovators and so much more. We believe amazing games and experiences start with teams as diverse as the players and communities we serve. At Electronic Arts, the only limit is your imagination.", 'job_posted_at_timestamp': 1695805677, 'job_posted_at_datetime_utc': '2023-09-27T09:07:57.000Z', 'tag': 'da', 'skills': ['database querying', 'data analysis', 'data visualization', 'statistical modelling']}]
[2023-09-27T23:58:58.801+0000] {taskinstance.py:1847} ERROR - Task failed with exception
Traceback (most recent call last):
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/decorators/base.py", line 220, in execute
    return_value = super().execute(context)
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 181, in execute
    return_value = self.execute_callable()
  File "/home/airflow/.local/lib/python3.9/site-packages/airflow/operators/python.py", line 198, in execute_callable
    return self.python_callable(*self.op_args, **self.op_kwargs)
  File "/opt/airflow/dags/ETL.py", line 95, in insert_into_database
    cassandra_manager=CassandraSessions(keyspace='job_data')
  File "/opt/airflow/dags/database.py", line 12, in __init__
    self.cluster = Cluster(nodes)
  File "cassandra/cluster.py", line 1191, in cassandra.cluster.Cluster.__init__
cassandra.UnresolvableContactPoints: {}
[2023-09-27T23:58:58.818+0000] {taskinstance.py:1368} INFO - Marking task as FAILED. dag_id=job_extraction_with_task_flow, task_id=insert_into_database, execution_date=20230927T235550, start_date=20230927T235858, end_date=20230927T235858
[2023-09-27T23:58:58.824+0000] {standard_task_runner.py:104} ERROR - Failed to execute job 4 for task insert_into_database ({}; 412)
[2023-09-27T23:58:58.859+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 1
[2023-09-27T23:58:58.872+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
