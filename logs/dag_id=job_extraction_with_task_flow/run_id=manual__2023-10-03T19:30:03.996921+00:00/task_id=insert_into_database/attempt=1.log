[2023-10-03T19:32:56.127+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=non-requeueable deps ti=<TaskInstance: job_extraction_with_task_flow.insert_into_database manual__2023-10-03T19:30:03.996921+00:00 [queued]>
[2023-10-03T19:32:56.134+0000] {taskinstance.py:1125} INFO - Dependencies all met for dep_context=requeueable deps ti=<TaskInstance: job_extraction_with_task_flow.insert_into_database manual__2023-10-03T19:30:03.996921+00:00 [queued]>
[2023-10-03T19:32:56.135+0000] {taskinstance.py:1331} INFO - Starting attempt 1 of 1
[2023-10-03T19:32:56.141+0000] {taskinstance.py:1350} INFO - Executing <Task(_PythonDecoratedOperator): insert_into_database> on 2023-10-03 19:30:03.996921+00:00
[2023-10-03T19:32:56.146+0000] {standard_task_runner.py:57} INFO - Started process 413 to run task
[2023-10-03T19:32:56.149+0000] {standard_task_runner.py:84} INFO - Running: ['***', 'tasks', 'run', 'job_extraction_with_task_flow', 'insert_into_database', 'manual__2023-10-03T19:30:03.996921+00:00', '--job-id', '4', '--raw', '--subdir', 'DAGS_FOLDER/ETL.py', '--cfg-path', '/tmp/tmp8xfryw53']
[2023-10-03T19:32:56.152+0000] {standard_task_runner.py:85} INFO - Job 4: Subtask insert_into_database
[2023-10-03T19:32:56.163+0000] {logging_mixin.py:149} WARNING - /home/***/.local/lib/python3.9/site-packages/***/settings.py:188 DeprecationWarning: The sql_alchemy_conn option in [core] has been moved to the sql_alchemy_conn option in [database] - the old setting has been used, but please update your config.
[2023-10-03T19:32:56.189+0000] {task_command.py:410} INFO - Running <TaskInstance: job_extraction_with_task_flow.insert_into_database manual__2023-10-03T19:30:03.996921+00:00 [running]> on host a19f7e7baf22
[2023-10-03T19:32:56.250+0000] {taskinstance.py:1568} INFO - Exporting env vars: AIRFLOW_CTX_DAG_OWNER='***' AIRFLOW_CTX_DAG_ID='job_extraction_with_task_flow' AIRFLOW_CTX_TASK_ID='insert_into_database' AIRFLOW_CTX_EXECUTION_DATE='2023-10-03T19:30:03.996921+00:00' AIRFLOW_CTX_TRY_NUMBER='1' AIRFLOW_CTX_DAG_RUN_ID='manual__2023-10-03T19:30:03.996921+00:00'
[2023-10-03T19:32:56.253+0000] {logging_mixin.py:149} INFO - Results [{'employer_name': 'Sony Playstation', 'job_employment_type': 'FULLTIME', 'job_title': 'Machine Learning Engineer', 'job_apply_link': 'https://ca.bebee.com/job/20231003-c96be63288b1f170acd3febd73dac9fd', 'job_description': "Why PlayStation?\n\nPlayStation isn't just the Best Place to Play — it's also the Best Place to Work. Today, we're recognized as a global leader in entertainment producing The PlayStation family of products and services including PlayStation5, PlayStation4, PlayStationVR, PlayStationPlus, acclaimed PlayStation software titles from PlayStation Studios, and more.\n\nPlayStation also strives to create an inclusive environment that empowers employees and embraces diversity. We welcome and encourage everyone who has a passion and curiosity for innovation, technology, and play to explore our open positions and join our growing global team.\n\nThe PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation.\nJoin the award-winning team that created God of War\n\nSanta Monica Studio is seeking an engineer passionate about pursuing cutting-edge research in machine learning as it pertains to a wide variety of areas of game development\n\nThe ideal candidate has strong expertise in machine learning / deep learning and is dedicated to creatively applying research and owning the implementation of software that changes the way games are made. If you're interested in helping us take our genre-defining games to the next level, come join our team\nResponsibilities\n• Collaborate with technical leadership, designers, animators, and programmers to determine how to best apply machine learning concepts to different areas of game development\n• Act as a point of contact for machine learning initiatives both within engineering and with its stakeholders\n• Prototype rapidly to take initiatives from ideation to working proof of concepts\n• Scale proof of concepts into production quality solutions\n• Write clear, maintainable, portable, and highly functional code\n• Profile and optimize to remove bottlenecks\n• Test and document code produced\nRequirements\n• 2+ years of experience in a machine learning / deep learning-focused role\n• Knowledge of standard machine learning and deep learning frameworks and libraries such as TensorFlow, PyTorch, NumPy, and Pandas\n• Knowledge of at least one technical area of game development\n• At least one shipped game title as a programmer\n• Strong programming skills in C++ and Python\n• A strong sense of ownership and initiative\n• Excellent spoken and written communication\n\n#LI-SMS\n#LI-AM1\n\nPlease refer to our Candidate Privacy Notice for more information about how we process your personal information, and your data protection rights.\n\nAt SIE, we consider several factors when setting each role's base pay range, including the competitive benchmarking data for the market and geographic location.\n\nPlease note that the base pay range may vary in line with our hybrid working policy and individual base pay will be determined based on job-related factors which may include knowledge, skills, experience, and location.\n\nIn addition, this role is eligible for SIE's top-tier benefits package that includes medical, dental, vision, matching 401(k), paid time off, wellness program and coveted employee discounts for Sony products. This role also may be eligible for a bonus package. Click here to learn more.\n\nThe estimated base pay range for this role is listed below.\n\n$127,600 — $191,400 USD\n\nEqual Opportunity Statement:\n\nSony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to gender (including gender identity, gender expression and gender reassignment), race (including colour, nationality, ethnic or national origin), religion or belief, marital or civil partnership status, disability, age, sexual orientation, pregnancy or maternity, trade union membership or membership in any other legally protected category.\n\nWe strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond.\n\nPlayStation is a Fair Chance employer and qualified applicants with arrest and conviction records will be considered for employment.", 'job_posted_at_timestamp': 1696301317, 'job_posted_at_datetime_utc': '2023-10-03T02:48:37.000Z', 'tag': 'ml', 'skills': ['machine learning', 'deep learning', 'game development', 'c++', 'python']}, {'employer_name': 'Sony Playstation', 'job_employment_type': 'FULLTIME', 'job_title': 'Machine Learning Engineer', 'job_apply_link': 'https://ca.bebee.com/job/20231003-c96be63288b1f170acd3febd73dac9fd', 'job_description': "Why PlayStation?\n\nPlayStation isn't just the Best Place to Play — it's also the Best Place to Work. Today, we're recognized as a global leader in entertainment producing The PlayStation family of products and services including PlayStation5, PlayStation4, PlayStationVR, PlayStationPlus, acclaimed PlayStation software titles from PlayStation Studios, and more.\n\nPlayStation also strives to create an inclusive environment that empowers employees and embraces diversity. We welcome and encourage everyone who has a passion and curiosity for innovation, technology, and play to explore our open positions and join our growing global team.\n\nThe PlayStation brand falls under Sony Interactive Entertainment, a wholly-owned subsidiary of Sony Corporation.\nJoin the award-winning team that created God of War\n\nSanta Monica Studio is seeking an engineer passionate about pursuing cutting-edge research in machine learning as it pertains to a wide variety of areas of game development\n\nThe ideal candidate has strong expertise in machine learning / deep learning and is dedicated to creatively applying research and owning the implementation of software that changes the way games are made. If you're interested in helping us take our genre-defining games to the next level, come join our team\nResponsibilities\n• Collaborate with technical leadership, designers, animators, and programmers to determine how to best apply machine learning concepts to different areas of game development\n• Act as a point of contact for machine learning initiatives both within engineering and with its stakeholders\n• Prototype rapidly to take initiatives from ideation to working proof of concepts\n• Scale proof of concepts into production quality solutions\n• Write clear, maintainable, portable, and highly functional code\n• Profile and optimize to remove bottlenecks\n• Test and document code produced\nRequirements\n• 2+ years of experience in a machine learning / deep learning-focused role\n• Knowledge of standard machine learning and deep learning frameworks and libraries such as TensorFlow, PyTorch, NumPy, and Pandas\n• Knowledge of at least one technical area of game development\n• At least one shipped game title as a programmer\n• Strong programming skills in C++ and Python\n• A strong sense of ownership and initiative\n• Excellent spoken and written communication\n\n#LI-SMS\n#LI-AM1\n\nPlease refer to our Candidate Privacy Notice for more information about how we process your personal information, and your data protection rights.\n\nAt SIE, we consider several factors when setting each role's base pay range, including the competitive benchmarking data for the market and geographic location.\n\nPlease note that the base pay range may vary in line with our hybrid working policy and individual base pay will be determined based on job-related factors which may include knowledge, skills, experience, and location.\n\nIn addition, this role is eligible for SIE's top-tier benefits package that includes medical, dental, vision, matching 401(k), paid time off, wellness program and coveted employee discounts for Sony products. This role also may be eligible for a bonus package. Click here to learn more.\n\nThe estimated base pay range for this role is listed below.\n\n$127,600 — $191,400 USD\n\nEqual Opportunity Statement:\n\nSony is an Equal Opportunity Employer. All persons will receive consideration for employment without regard to gender (including gender identity, gender expression and gender reassignment), race (including colour, nationality, ethnic or national origin), religion or belief, marital or civil partnership status, disability, age, sexual orientation, pregnancy or maternity, trade union membership or membership in any other legally protected category.\n\nWe strive to create an inclusive environment, empower employees and embrace diversity. We encourage everyone to respond.\n\nPlayStation is a Fair Chance employer and qualified applicants with arrest and conviction records will be considered for employment.", 'job_posted_at_timestamp': 1696301317, 'job_posted_at_datetime_utc': '2023-10-03T02:48:37.000Z', 'tag': 'ml', 'skills': ['machine learning', 'deep learning', 'game development', 'c++', 'python']}, {'employer_name': 'Adastra Corporation', 'job_employment_type': 'FULLTIME', 'job_title': 'Senior AI Specialist', 'job_apply_link': 'https://emplois.ca.indeed.com/viewjob?jk=6ed4a2a4693fe93f', 'job_description': "Overview:\n\nAdastra corporation is hiring! As Canada’s leading Data and AI company, we are looking for a Senior AI Specialist to work with a team of Adastra consultants in delivering high-impact Advanced Analytics and Data Science projects.\n\nThe Senior AI Specialist will employ cutting-edge methodologies and robust analytical techniques to generate insights and create innovative models that enable our clients to uncover untapped revenue streams, optimize operational efficiencies, and mitigate risks.\n\nLocation: Hybrid (Toronto/Markham)\n\nStatus: Full-Time\n\nResponsibilities:\n• Gather business requirements and identify opportunities for analytics and AI\n• Extract, validate, and consolidate data from disparate sources\n• Ensure compliance with data governance and architectural strategies\n• Explore and apply model development toolkits and machine learning approaches\n• Refactor and scale models for efficiency\n• Deploy data preparation and model pipelines to client environments\n• Present analytical results to technical and non-technical audiences using visualization tools\n• Adhere to development best practices\n\nQualifications, Skills & Experience:\n• Undergraduate in STEM; Master's/Ph.D. preferred\n• 2+ years of experience solving practical business problems\n• Experience with data collection, data audits, cleaning/imputing, and deriving aggregate measures and business metrics\n• Advanced proficiency in Python with expertise in programming, data analysis, cleaning, visualization, modeling, statistical analysis, and deployment\n• Proficient in programming languages like Java or C++, including ability to write efficient and scalable code for building mathematical models and optimization algorithms\n• Experience with analytical tools and frameworks such as Pandas, NumPy, Scikit-learn, Keras, TensorFlow, PyTorch, etc.\n• Familiarity with SQL and relational database management systems\n• Experience training and scaling models, including predictive and prescriptive analytics applications\n• Understanding of statistical principles and distributions\n• Experience deploying and managing applications in the cloud (AWS, Azure, and/or GCP)\n• Knowledge of software development practices, such as version control systems, DevOps, and collaborative toolsets\n• Familiarity with Natural Language Processing (NLP) techniques and tools, which can be used to analyze and understand natural language data\n• Familiarity with big data technologies, such as Hadoop, Spark, and NoSQL databases.\n• Project management skills include ability to manage deadlines, collaborate with team members, and prioritize tasks\n\nRequired Soft Skills:\n• Strong problem-solving skills: ability to analyze and solve practical/complex business problems using AI, machine learning, mathematical modeling and optimization techniques\n• Ability to work collaboratively with other team members and clients to identify opportunities for analytics and AI\n• Strong communication skills are essential: ability to write and communicate clear and concise technical concepts, documentation, reports, and presentations to non-technical stakeholders\n• Critical thinking skills: ability to assess the feasibility and effectiveness of different models and methods, identify potential risks and limitations, and make data-driven decisions\n• Creative thinking skills: ability to develop innovative solutions to complex problems and to think outside the box when traditional methods do not work\n\nAbout Adastra\n\nAt Adastra, we transform the Data & Analytics space by providing cutting-edge Artificial Intelligence, Big Data, Cloud, Digital and Governance services. Our consultants specialize in transforming enterprise applications and collaborate across functions, competencies, and sectors to help our clients harness and leverage their data assets, accelerate innovation, improve operational excellence, and create unforgettable customer experiences.\n\nAdastra has been recognized as one of Canada’s Best Managed Companies for 20 consecutive years, reinforcing our position as a best-in-class organization known for strategic excellence, innovation, and culture. People are at the core of Adastra's capabilities, and the Adastra Group has 2,500 consultants actualizing projects across 16 global branches.\n\nThere has been an increased instance of fraudulent job offers coming from people posing as Adastra HR employees. Please note that Adastra will never request fees as part of our recruiting process and any emails sent to you that are not from ‘@adastragrp.com’ or ‘@talent.icims.com’ are fraudulent. All employment offers are sent via DocuSign and if you receive an employment offer from a suspicious email and not via DocuSign, it is fraudulent.\n\nContact careers@adastragrp.com to inquire about jobs at Adastra, to report a suspicious request for money or personal information from external websites or suspicious employment offers.\n\nWhat We Offer\n• Opportunity for advancement and career progression\n• Competitive compensation package\n• Comprehensive benefits plan\n• Successful referral program\n• A flexible and dynamic workplace\n• The opportunity to work with one of Canada’s 50 Best Managed Companies\n• Satisfaction of working for a reputable company\n\nEqual Opportunity Employer\n\nIn our commitment to promote fair and equitable treatment of all employees and applicants, Adastra Corporation provides equal employment opportunities for all individuals regardless of age, sex, disability, race, ethnic origin, citizenship, creed, sexual orientation, marital status or any other ground as described in the Ontario Human Rights Code. In addition, accommodation will be provided during the hiring process. Adastra Corporation’s implementation and support of employment initiatives, encourage diversified labour force participation and equal access to opportunities based on merit and performance.", 'job_posted_at_timestamp': 1696293659, 'job_posted_at_datetime_utc': '2023-10-03T00:40:59.000Z', 'tag': 'ml', 'skills': ['creative thinking']}, {'employer_name': 'Adastra Corporation', 'job_employment_type': 'FULLTIME', 'job_title': 'Senior AI Specialist', 'job_apply_link': 'https://emplois.ca.indeed.com/viewjob?jk=6ed4a2a4693fe93f', 'job_description': "Overview:\n\nAdastra corporation is hiring! As Canada’s leading Data and AI company, we are looking for a Senior AI Specialist to work with a team of Adastra consultants in delivering high-impact Advanced Analytics and Data Science projects.\n\nThe Senior AI Specialist will employ cutting-edge methodologies and robust analytical techniques to generate insights and create innovative models that enable our clients to uncover untapped revenue streams, optimize operational efficiencies, and mitigate risks.\n\nLocation: Hybrid (Toronto/Markham)\n\nStatus: Full-Time\n\nResponsibilities:\n• Gather business requirements and identify opportunities for analytics and AI\n• Extract, validate, and consolidate data from disparate sources\n• Ensure compliance with data governance and architectural strategies\n• Explore and apply model development toolkits and machine learning approaches\n• Refactor and scale models for efficiency\n• Deploy data preparation and model pipelines to client environments\n• Present analytical results to technical and non-technical audiences using visualization tools\n• Adhere to development best practices\n\nQualifications, Skills & Experience:\n• Undergraduate in STEM; Master's/Ph.D. preferred\n• 2+ years of experience solving practical business problems\n• Experience with data collection, data audits, cleaning/imputing, and deriving aggregate measures and business metrics\n• Advanced proficiency in Python with expertise in programming, data analysis, cleaning, visualization, modeling, statistical analysis, and deployment\n• Proficient in programming languages like Java or C++, including ability to write efficient and scalable code for building mathematical models and optimization algorithms\n• Experience with analytical tools and frameworks such as Pandas, NumPy, Scikit-learn, Keras, TensorFlow, PyTorch, etc.\n• Familiarity with SQL and relational database management systems\n• Experience training and scaling models, including predictive and prescriptive analytics applications\n• Understanding of statistical principles and distributions\n• Experience deploying and managing applications in the cloud (AWS, Azure, and/or GCP)\n• Knowledge of software development practices, such as version control systems, DevOps, and collaborative toolsets\n• Familiarity with Natural Language Processing (NLP) techniques and tools, which can be used to analyze and understand natural language data\n• Familiarity with big data technologies, such as Hadoop, Spark, and NoSQL databases.\n• Project management skills include ability to manage deadlines, collaborate with team members, and prioritize tasks\n\nRequired Soft Skills:\n• Strong problem-solving skills: ability to analyze and solve practical/complex business problems using AI, machine learning, mathematical modeling and optimization techniques\n• Ability to work collaboratively with other team members and clients to identify opportunities for analytics and AI\n• Strong communication skills are essential: ability to write and communicate clear and concise technical concepts, documentation, reports, and presentations to non-technical stakeholders\n• Critical thinking skills: ability to assess the feasibility and effectiveness of different models and methods, identify potential risks and limitations, and make data-driven decisions\n• Creative thinking skills: ability to develop innovative solutions to complex problems and to think outside the box when traditional methods do not work\n\nAbout Adastra\n\nAt Adastra, we transform the Data & Analytics space by providing cutting-edge Artificial Intelligence, Big Data, Cloud, Digital and Governance services. Our consultants specialize in transforming enterprise applications and collaborate across functions, competencies, and sectors to help our clients harness and leverage their data assets, accelerate innovation, improve operational excellence, and create unforgettable customer experiences.\n\nAdastra has been recognized as one of Canada’s Best Managed Companies for 20 consecutive years, reinforcing our position as a best-in-class organization known for strategic excellence, innovation, and culture. People are at the core of Adastra's capabilities, and the Adastra Group has 2,500 consultants actualizing projects across 16 global branches.\n\nThere has been an increased instance of fraudulent job offers coming from people posing as Adastra HR employees. Please note that Adastra will never request fees as part of our recruiting process and any emails sent to you that are not from ‘@adastragrp.com’ or ‘@talent.icims.com’ are fraudulent. All employment offers are sent via DocuSign and if you receive an employment offer from a suspicious email and not via DocuSign, it is fraudulent.\n\nContact careers@adastragrp.com to inquire about jobs at Adastra, to report a suspicious request for money or personal information from external websites or suspicious employment offers.\n\nWhat We Offer\n• Opportunity for advancement and career progression\n• Competitive compensation package\n• Comprehensive benefits plan\n• Successful referral program\n• A flexible and dynamic workplace\n• The opportunity to work with one of Canada’s 50 Best Managed Companies\n• Satisfaction of working for a reputable company\n\nEqual Opportunity Employer\n\nIn our commitment to promote fair and equitable treatment of all employees and applicants, Adastra Corporation provides equal employment opportunities for all individuals regardless of age, sex, disability, race, ethnic origin, citizenship, creed, sexual orientation, marital status or any other ground as described in the Ontario Human Rights Code. In addition, accommodation will be provided during the hiring process. Adastra Corporation’s implementation and support of employment initiatives, encourage diversified labour force participation and equal access to opportunities based on merit and performance.", 'job_posted_at_timestamp': 1696293659, 'job_posted_at_datetime_utc': '2023-10-03T00:40:59.000Z', 'tag': 'ml', 'skills': ['creative thinking']}, {'employer_name': '1206067 B.C. LTD.', 'job_employment_type': 'FULLTIME', 'job_title': 'data analyst', 'job_apply_link': 'https://ca.bebee.com/job/20231003-ca88be47077a16a1df9f0ade13fadac7', 'job_description': "Education:\nCollege, CEGEP or other non-university certificate or diploma from a program of 1 year to 2 years Experience: 3 years to less than 5 years Work setting Private sector Tasks Collect and document user's requirements Data Science Design and develop database Design, construct, modify, implement and test data models and database management systems Operate database management systems to analyze data Research and document data requirements, data collection and administration policy, and data access rules Develop policies and procedures for network access and usage and for the backup and recovery of data Computer and technology knowledge Data Warehouse Security software Database software Programming languages Data analysis software SQL Business intelligence Work conditions and physical capabilities Fast-paced environment Tight deadlines Attention to detail Personal suitability Accurate Excellent oral communication Organized Team player Screening questions Do you have previous experience in this field of employment? Other benefits Free parking available Variable or compressed work week\n\nWork Term:\n\nPermanent Work Language:\nEnglish Hours: 35 hours per week", 'job_posted_at_timestamp': 1696297895, 'job_posted_at_datetime_utc': '2023-10-03T01:51:35.000Z', 'tag': 'ds', 'skills': ['education', 'experience', 'work setting', 'tasks', 'tech savvy', 'work conditions', 'personal suitability', 'screening questions', 'work term', 'work language', 'hours']}, {'employer_name': '1206067 B.C. LTD.', 'job_employment_type': 'FULLTIME', 'job_title': 'data analyst', 'job_apply_link': 'https://ca.bebee.com/job/20231003-ca88be47077a16a1df9f0ade13fadac7', 'job_description': "Education:\nCollege, CEGEP or other non-university certificate or diploma from a program of 1 year to 2 years Experience: 3 years to less than 5 years Work setting Private sector Tasks Collect and document user's requirements Data Science Design and develop database Design, construct, modify, implement and test data models and database management systems Operate database management systems to analyze data Research and document data requirements, data collection and administration policy, and data access rules Develop policies and procedures for network access and usage and for the backup and recovery of data Computer and technology knowledge Data Warehouse Security software Database software Programming languages Data analysis software SQL Business intelligence Work conditions and physical capabilities Fast-paced environment Tight deadlines Attention to detail Personal suitability Accurate Excellent oral communication Organized Team player Screening questions Do you have previous experience in this field of employment? Other benefits Free parking available Variable or compressed work week\n\nWork Term:\n\nPermanent Work Language:\nEnglish Hours: 35 hours per week", 'job_posted_at_timestamp': 1696297895, 'job_posted_at_datetime_utc': '2023-10-03T01:51:35.000Z', 'tag': 'ds', 'skills': ['education', 'experience', 'work setting', 'tasks', 'tech savvy', 'work conditions', 'personal suitability', 'screening questions', 'work term', 'work language', 'hours']}, {'employer_name': 'Coursera', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Engineer', 'job_apply_link': 'https://simplify.jobs/p/a55cab97-6f94-4a94-917e-6833c45795b4/Data-Engineer', 'job_description': 'Coursera was launched in 2012 by two Stanford Computer Science professors, Andrew Ng and Daphne Koller, with a mission to provide universal access to world-class learning. It is now one of the largest online learning platforms in the world, with 129 million registered learners as of June 30, 2023.\n\nCoursera partners with over 300 leading university and industry partners to offer a broad catalog of content and credentials, including courses, Specializations, Professional Certificates, Guided Projects, and bachelor’s and master’s degrees. Institutions around the world use Coursera to upskill and reskill their employees, citizens, and students in fields such as data science, technology, and business. Coursera became a B Corp in February 2021.\n\nJoin us in our mission to create a world where anyone, anywhere can transform their life through access to education. We’re seeking talented individuals who share our passion and drive to revolutionize the way the world learns.\n\nWe at Coursera are committed to building a globally diverse team and are thrilled to extend employment opportunities to individuals in any country where we have a legal entity. We require candidates to possess eligible working rights and have a compatible timezone overlap with their team to facilitate seamless collaboration. As a remote-first company, our interviews and onboarding are entirely virtual, providing a smooth and efficient experience for our candidates.\n\nJob Description\n\nCoursera was launched in 2012 by two Stanford Computer Science professors, Andrew Ng and Daphne Koller, with a mission to provide universal access to world-class learning. It is now one of the largest online learning platforms in the world, with 113 million registered learners as of September 30, 2022. Coursera partners with over 275 leading university and industry partners to offer a broad catalog of content and credentials, including courses, Specializations, Professional Certificates, Guided Projects, and bachelor’s and master’s degrees. Institutions around the world use Coursera to upskill and reskill their employees, citizens, and students in fields such as data science, technology, and business. Coursera became a B Corp in February 2021.\n\nData Engineering is unique at Coursera. Our team doesn’t simply build reports on demand; rather, we build the semantic infrastructure and products that empower our internal and external customers with the data to innovate and perform their jobs better.\n\nWe’re looking for a talented and driven data engineer with a keen eye for data. In this role, you’ll directly work with cross-functional teams to design, develop, and deploy partner data solutions. Our ideal candidate is an independent, analytically-minded individual with strong data modeling and software engineering skills, who shares our passion for education.\n\nYou personally exhibit a conviction that the world needs Coursera to be wildly successful and alignment to our core values:\n• Betterment: a tireless pursuit to drive results\n• Boldness: take risks and act decisively\n• Deep Honesty: invite and offer candid feedback in order to learn, change, and grow\n• Solidarity: recognize that we are part of something bigger than ourselves and are committed to our mission\n\nYour responsibilities\n• Architect scalable data models and build efficient and reliable ETL pipelines to bring the data into our core data lake\n• Design, build, and launch visualization and self-serve analytics products that empower our internal and external customers with flexible insights\n• Build data expertise, and partner with data scientists and product engineers to define and standardize business rules and maintain high-fidelity data\n• Define and partner with other engineers in the development of new tools to enable our customers to understand and access data more efficiently\n• Work cross-functionally (eg: product managers, engineers, business teams) to support new product and feature launches\n\nYour skills\n• 1-3 years experience in a data-related field, including data engineering, data warehousing, business intelligence, data visualization, and/or data science\n• Strong software engineering skills and at least one scripting language (e.g., Python)\n• Proficient with relational databases and SQL\n• Familiarity and experience with big data technologies (eg: Hive, Spark, Presto) preferred\n• Ability to communicate technical concepts clearly and concisely\n• Independence and passion for innovation and learning new technologies\n\nBonus\n• Hands-on experience with AWS, Databricks, Delta Lake, Airflow, DBT, Redshift\n\nIf this opportunity interest you, you might like these courses on Coursera:\n• Big Data Specialization\n• Big Data Essentials - HDFS, MapReduce and Spark\n• Data Warehousing for Business Intelligence\n\n#LI-CP1\nCoursera is an Equal Employment Opportunity Employer and considers all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, age, marital status, national origin, protected veteran status, disability, or any other legally protected class.\n\nIf you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, please contact us at accommodations@coursera.org.\n\nFor California Candidates, please review our CCPA Applicant Notice here.\n\nFor our Global Candidates, please review our GDPR Recruitment Notice here.', 'job_posted_at_timestamp': 1696291200, 'job_posted_at_datetime_utc': '2023-10-03T00:00:00.000Z', 'tag': 'ds', 'skills': ['data modeling', 'etl pipelines', 'data visualization', 'sql', 'big data', 'software engineering', 'scripting language', 'aws', 'databricks', 'delta lake', '***', 'dbt', 'redshift']}, {'employer_name': 'Coursera', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Engineer', 'job_apply_link': 'https://simplify.jobs/p/a55cab97-6f94-4a94-917e-6833c45795b4/Data-Engineer', 'job_description': 'Coursera was launched in 2012 by two Stanford Computer Science professors, Andrew Ng and Daphne Koller, with a mission to provide universal access to world-class learning. It is now one of the largest online learning platforms in the world, with 129 million registered learners as of June 30, 2023.\n\nCoursera partners with over 300 leading university and industry partners to offer a broad catalog of content and credentials, including courses, Specializations, Professional Certificates, Guided Projects, and bachelor’s and master’s degrees. Institutions around the world use Coursera to upskill and reskill their employees, citizens, and students in fields such as data science, technology, and business. Coursera became a B Corp in February 2021.\n\nJoin us in our mission to create a world where anyone, anywhere can transform their life through access to education. We’re seeking talented individuals who share our passion and drive to revolutionize the way the world learns.\n\nWe at Coursera are committed to building a globally diverse team and are thrilled to extend employment opportunities to individuals in any country where we have a legal entity. We require candidates to possess eligible working rights and have a compatible timezone overlap with their team to facilitate seamless collaboration. As a remote-first company, our interviews and onboarding are entirely virtual, providing a smooth and efficient experience for our candidates.\n\nJob Description\n\nCoursera was launched in 2012 by two Stanford Computer Science professors, Andrew Ng and Daphne Koller, with a mission to provide universal access to world-class learning. It is now one of the largest online learning platforms in the world, with 113 million registered learners as of September 30, 2022. Coursera partners with over 275 leading university and industry partners to offer a broad catalog of content and credentials, including courses, Specializations, Professional Certificates, Guided Projects, and bachelor’s and master’s degrees. Institutions around the world use Coursera to upskill and reskill their employees, citizens, and students in fields such as data science, technology, and business. Coursera became a B Corp in February 2021.\n\nData Engineering is unique at Coursera. Our team doesn’t simply build reports on demand; rather, we build the semantic infrastructure and products that empower our internal and external customers with the data to innovate and perform their jobs better.\n\nWe’re looking for a talented and driven data engineer with a keen eye for data. In this role, you’ll directly work with cross-functional teams to design, develop, and deploy partner data solutions. Our ideal candidate is an independent, analytically-minded individual with strong data modeling and software engineering skills, who shares our passion for education.\n\nYou personally exhibit a conviction that the world needs Coursera to be wildly successful and alignment to our core values:\n• Betterment: a tireless pursuit to drive results\n• Boldness: take risks and act decisively\n• Deep Honesty: invite and offer candid feedback in order to learn, change, and grow\n• Solidarity: recognize that we are part of something bigger than ourselves and are committed to our mission\n\nYour responsibilities\n• Architect scalable data models and build efficient and reliable ETL pipelines to bring the data into our core data lake\n• Design, build, and launch visualization and self-serve analytics products that empower our internal and external customers with flexible insights\n• Build data expertise, and partner with data scientists and product engineers to define and standardize business rules and maintain high-fidelity data\n• Define and partner with other engineers in the development of new tools to enable our customers to understand and access data more efficiently\n• Work cross-functionally (eg: product managers, engineers, business teams) to support new product and feature launches\n\nYour skills\n• 1-3 years experience in a data-related field, including data engineering, data warehousing, business intelligence, data visualization, and/or data science\n• Strong software engineering skills and at least one scripting language (e.g., Python)\n• Proficient with relational databases and SQL\n• Familiarity and experience with big data technologies (eg: Hive, Spark, Presto) preferred\n• Ability to communicate technical concepts clearly and concisely\n• Independence and passion for innovation and learning new technologies\n\nBonus\n• Hands-on experience with AWS, Databricks, Delta Lake, Airflow, DBT, Redshift\n\nIf this opportunity interest you, you might like these courses on Coursera:\n• Big Data Specialization\n• Big Data Essentials - HDFS, MapReduce and Spark\n• Data Warehousing for Business Intelligence\n\n#LI-CP1\nCoursera is an Equal Employment Opportunity Employer and considers all qualified applicants without regard to race, color, religion, sex, sexual orientation, gender identity, age, marital status, national origin, protected veteran status, disability, or any other legally protected class.\n\nIf you are an individual with a disability and require a reasonable accommodation to complete any part of the application process, please contact us at accommodations@coursera.org.\n\nFor California Candidates, please review our CCPA Applicant Notice here.\n\nFor our Global Candidates, please review our GDPR Recruitment Notice here.', 'job_posted_at_timestamp': 1696291200, 'job_posted_at_datetime_utc': '2023-10-03T00:00:00.000Z', 'tag': 'ds', 'skills': ['data modeling', 'etl pipelines', 'data visualization', 'sql', 'big data', 'software engineering', 'scripting language', 'aws', 'databricks', 'delta lake', '***', 'dbt', 'redshift']}, {'employer_name': 'Ripple', 'job_employment_type': 'FULLTIME', 'job_title': 'Software Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/software-engineer-at-ripple-3727252225', 'job_description': 'At Ripple, we’re building a world where value moves like information does today. It’s big, it’s bold, and we’re already doing it. Through our crypto solutions for financial institutions, businesses, governments and developers, we are improving the global financial system and creating greater economic fairness and opportunity for more people, in more places around the world. And we get to do the best work of our career and grow our skills surrounded by colleagues who have our backs.\n\nIf you’re ready to see your impact and unlock incredible career growth opportunities, join us, and build real world value.\n\nAt Ripple, we’re building a world where value moves like information does today. It’s big, it’s bold, and we’re already doing it. Through our crypto solutions for financial institutions, businesses, governments, and developers, we are improving the global financial system and creating greater economic fairness and opportunity for more people, in more places around the world. And we get to do the best work of our careers and grow our skills surrounded by colleagues who have our backs.\n\nIf you’re ready to see your impact and unlock incredible career growth opportunities, join us, and build real-world value.\n\nThe Work\n\nThe RippleX CBDC team is at the forefront of delivering on this vision. We are engaging with central and commercial banks across the world to learn how to offer the solutions they need in order to issue currency digitally on a blockchain. We are looking for Software Engineers passionate about solving challenging problems in the finance and/or crypto space. We are passionate about the growth of our engineers and place a premium on career development. You will have a high degree of accountability and responsibility from Day 1.\n\nWhat You’ll Do\n• Build enterprise, distributed blockchain adjacent services to power CBDC solutions for our customers.\n• Deliver reliable, high-throughput, low-latency applications supporting complex systems of financial asset management.\n• Participate in the full software development lifecycle by gathering requirements, leveraging sound software design principles, and ensuring operational excellence with unit & integration testing\n• Work with teams across the organization, including product, legal, and business development to think beyond the technical implications of your design decisions\n• Continuously raise our standard of engineering excellence by implementing and driving best practices for coding, testing, and deployment\n\nWhat You’ll Bring\n• 2-5 years of hands-on software development experience on large scale, transactional systems with a focus on robust software design, scalability and security\n• Hands on experience with Java 2+ and popular Java based frameworks like Spring and Hibernate.\n• Familiarity with RESTful web services and best practices.\n• Familiarity with using asynchronous technologies like Kafka, PubSub, SNS/SQS, RabbitMQ, etc.\n• Intellectual curiosity - you love to dig into how things work and understand how to improve and scale them\n• You thrive on autonomy, responsibility and owning your work, end to end\n• A positive attitude and a passion for sharing knowledge within your team and organization\n• Eagerness to work openly and collaboratively with a diverse team\n\nWho We Are\n\nDo Your Best Work\n• The opportunity to build in a fast-paced start-up environment with experienced industry leaders\n• A learning environment where you can dive deep into the latest technologies and make an impact. A professional development budget to support other modes of learning.\n• Thrive in an environment where no matter what race, ethnicity, gender, origin, or culture they identify with, every employee is a respected, valued, and empowered part of the team.\n• Ripple is Flexible First: you have the option to work from home, from our offices, or a combination of the two around our centers of gravity (15 global offices).\n• Weekly all-company meeting - business updates and ask me anything style discussion with our Leadership Team\n• We come together for moments that matter which include team offsites, team bonding activities, happy hours and more!\n\nTake Control of Your Finances\n• Competitive salary, bonuses, and equity\n• Competitive benefits that cover physical and mental healthcare, retirement, family forming, and family support\n• Employee giving match\n• Mobile phone stipend\n\nTake Care of Yourself\n• Twice a quarter R&R days so you can rest and recharge\n• Generous wellness reimbursement and weekly onsite & virtual programming\n• Generous vacation policy - work with your manager to take time off when you need it\n• Industry-leading parental leave policies. Family planning benefits.\n• Catered lunches, fully-stocked kitchens with premium snacks/beverages, and plenty of fun events\n\nBenefits listed above are for full-time Ripple employees. For all Metaco roles, please discuss benefits with your recruiter.\n\nRipple is an Equal Opportunity Employer. We’re committed to building a diverse and inclusive team. We do not discriminate against qualified employees or applicants because of race, color, religion, gender identity, sex, sexual identity, pregnancy, national origin, ancestry, citizenship, age, marital status, physical disability, mental disability, medical condition, military status, or any other characteristic protected by local law or ordinance.\n\nPlease find our UK/EU Applicant Privacy Notice and our California Applicant Privacy Notice for reference.', 'job_posted_at_timestamp': 1696285357, 'job_posted_at_datetime_utc': '2023-10-02T22:22:37.000Z', 'tag': 'se', 'skills': ['java', 'spring', 'hibernate', 'web services', 'kafka', 'pubsub', 'sns/sqs', 'rabbitmq']}, {'employer_name': 'Ripple', 'job_employment_type': 'FULLTIME', 'job_title': 'Software Engineer', 'job_apply_link': 'https://ca.linkedin.com/jobs/view/software-engineer-at-ripple-3727252225', 'job_description': 'At Ripple, we’re building a world where value moves like information does today. It’s big, it’s bold, and we’re already doing it. Through our crypto solutions for financial institutions, businesses, governments and developers, we are improving the global financial system and creating greater economic fairness and opportunity for more people, in more places around the world. And we get to do the best work of our career and grow our skills surrounded by colleagues who have our backs.\n\nIf you’re ready to see your impact and unlock incredible career growth opportunities, join us, and build real world value.\n\nAt Ripple, we’re building a world where value moves like information does today. It’s big, it’s bold, and we’re already doing it. Through our crypto solutions for financial institutions, businesses, governments, and developers, we are improving the global financial system and creating greater economic fairness and opportunity for more people, in more places around the world. And we get to do the best work of our careers and grow our skills surrounded by colleagues who have our backs.\n\nIf you’re ready to see your impact and unlock incredible career growth opportunities, join us, and build real-world value.\n\nThe Work\n\nThe RippleX CBDC team is at the forefront of delivering on this vision. We are engaging with central and commercial banks across the world to learn how to offer the solutions they need in order to issue currency digitally on a blockchain. We are looking for Software Engineers passionate about solving challenging problems in the finance and/or crypto space. We are passionate about the growth of our engineers and place a premium on career development. You will have a high degree of accountability and responsibility from Day 1.\n\nWhat You’ll Do\n• Build enterprise, distributed blockchain adjacent services to power CBDC solutions for our customers.\n• Deliver reliable, high-throughput, low-latency applications supporting complex systems of financial asset management.\n• Participate in the full software development lifecycle by gathering requirements, leveraging sound software design principles, and ensuring operational excellence with unit & integration testing\n• Work with teams across the organization, including product, legal, and business development to think beyond the technical implications of your design decisions\n• Continuously raise our standard of engineering excellence by implementing and driving best practices for coding, testing, and deployment\n\nWhat You’ll Bring\n• 2-5 years of hands-on software development experience on large scale, transactional systems with a focus on robust software design, scalability and security\n• Hands on experience with Java 2+ and popular Java based frameworks like Spring and Hibernate.\n• Familiarity with RESTful web services and best practices.\n• Familiarity with using asynchronous technologies like Kafka, PubSub, SNS/SQS, RabbitMQ, etc.\n• Intellectual curiosity - you love to dig into how things work and understand how to improve and scale them\n• You thrive on autonomy, responsibility and owning your work, end to end\n• A positive attitude and a passion for sharing knowledge within your team and organization\n• Eagerness to work openly and collaboratively with a diverse team\n\nWho We Are\n\nDo Your Best Work\n• The opportunity to build in a fast-paced start-up environment with experienced industry leaders\n• A learning environment where you can dive deep into the latest technologies and make an impact. A professional development budget to support other modes of learning.\n• Thrive in an environment where no matter what race, ethnicity, gender, origin, or culture they identify with, every employee is a respected, valued, and empowered part of the team.\n• Ripple is Flexible First: you have the option to work from home, from our offices, or a combination of the two around our centers of gravity (15 global offices).\n• Weekly all-company meeting - business updates and ask me anything style discussion with our Leadership Team\n• We come together for moments that matter which include team offsites, team bonding activities, happy hours and more!\n\nTake Control of Your Finances\n• Competitive salary, bonuses, and equity\n• Competitive benefits that cover physical and mental healthcare, retirement, family forming, and family support\n• Employee giving match\n• Mobile phone stipend\n\nTake Care of Yourself\n• Twice a quarter R&R days so you can rest and recharge\n• Generous wellness reimbursement and weekly onsite & virtual programming\n• Generous vacation policy - work with your manager to take time off when you need it\n• Industry-leading parental leave policies. Family planning benefits.\n• Catered lunches, fully-stocked kitchens with premium snacks/beverages, and plenty of fun events\n\nBenefits listed above are for full-time Ripple employees. For all Metaco roles, please discuss benefits with your recruiter.\n\nRipple is an Equal Opportunity Employer. We’re committed to building a diverse and inclusive team. We do not discriminate against qualified employees or applicants because of race, color, religion, gender identity, sex, sexual identity, pregnancy, national origin, ancestry, citizenship, age, marital status, physical disability, mental disability, medical condition, military status, or any other characteristic protected by local law or ordinance.\n\nPlease find our UK/EU Applicant Privacy Notice and our California Applicant Privacy Notice for reference.', 'job_posted_at_timestamp': 1696285357, 'job_posted_at_datetime_utc': '2023-10-02T22:22:37.000Z', 'tag': 'se', 'skills': ['java', 'spring', 'hibernate', 'web services', 'kafka', 'pubsub', 'sns/sqs', 'rabbitmq']}, {'employer_name': 'Intuit', 'job_employment_type': 'FULLTIME', 'job_title': 'Software Engineer 2', 'job_apply_link': 'https://ca.bebee.com/job/20231003-47f8bcc4c5100c68ee58d10393f63c66', 'job_description': 'Company Overview\n\nIntuit is a global technology platform that helps consumers and small businesses overcome their most important financial challenges. Serving more than 100 million customers worldwide with TurboTax, Credit Karma, QuickBooks, and Mailchimp, we believe that everyone should have the opportunity to prosper. We never stop working to find new, innovative ways to make that possible.\n\nJob Overview\n\nCome join the "Knowledge Driven Systems Group". You\'ll be part of a team developing the core Knowledge Engine (KE) tax technology that TurboTax is built on. We handle both the core KE capabilities as well as the authoring developer experiences and tooling to create content for these core capabilities. This technology is used by both our desktop and online offerings enabling millions of TurboTax customers to prepare their returns.\n\nAs a software engineer in the Tax Engine Group, you should have genuine interest in all software technology and will be directly responsible for design, development, testing, maintenance, and documentation of high-quality software components.\n\nQualifications\n• 2+ years of experience developing, maintaining, and innovating using Java (or other object oriented language)\n• Strong experience with Java (or other object oriented language) and various design patterns\n• Strong understanding of the Software design/architecture process\n• Experience with the entire Software Development Life Cycle (SDLC)\n• Solid communication skills: Demonstrated ability to explain complex technical issues to both technical and non-technical audiences\n• "Self-starter" attitude and ability to make decisions independently\n• Strong desire to learn and grow and a helpful, can-do attitude and a willingness to take ownership of problems\n• Experience with unit testing (TDD)\n\nResponsibilities\n• Gathering functional requirements, developing technical specifications, and project & test planning\n• Designing/developing prototypes, or proofs of concepts\n• Roughly 75-85% hands-on coding (including test)\n• Demonstrate end-to-end ownership and full cycle engineering mindset; responsible for integration, functional, unit and performance testing\n• Resolve defects/bugs during QA testing, pre-production, production, and post-release patches\n• Work cross-functionally with various Intuit teams or business units to drive forward results\n• Contribute to the design and architecture of the project\n• Work in an Agile Development environment\n• Develops a deep understanding of customer perspectives\n• Designs and implements solutions within the context of higher-level design, business, technology and user requirements and constraints\n• Understands how they fit into the overall business strategy, so they can support the organization\'s priorities. Continuously challenges effectiveness of internal processes, tools and systems, recommending changes, as appropriate', 'job_posted_at_timestamp': 1696318479, 'job_posted_at_datetime_utc': '2023-10-03T07:34:39.000Z', 'tag': 'se', 'skills': ['java', 'software design', 'software development', 'test-driven development', 'communication skills', 'problem-solving', 'agile development']}, {'employer_name': 'Intuit', 'job_employment_type': 'FULLTIME', 'job_title': 'Software Engineer 2', 'job_apply_link': 'https://ca.bebee.com/job/20231003-47f8bcc4c5100c68ee58d10393f63c66', 'job_description': 'Company Overview\n\nIntuit is a global technology platform that helps consumers and small businesses overcome their most important financial challenges. Serving more than 100 million customers worldwide with TurboTax, Credit Karma, QuickBooks, and Mailchimp, we believe that everyone should have the opportunity to prosper. We never stop working to find new, innovative ways to make that possible.\n\nJob Overview\n\nCome join the "Knowledge Driven Systems Group". You\'ll be part of a team developing the core Knowledge Engine (KE) tax technology that TurboTax is built on. We handle both the core KE capabilities as well as the authoring developer experiences and tooling to create content for these core capabilities. This technology is used by both our desktop and online offerings enabling millions of TurboTax customers to prepare their returns.\n\nAs a software engineer in the Tax Engine Group, you should have genuine interest in all software technology and will be directly responsible for design, development, testing, maintenance, and documentation of high-quality software components.\n\nQualifications\n• 2+ years of experience developing, maintaining, and innovating using Java (or other object oriented language)\n• Strong experience with Java (or other object oriented language) and various design patterns\n• Strong understanding of the Software design/architecture process\n• Experience with the entire Software Development Life Cycle (SDLC)\n• Solid communication skills: Demonstrated ability to explain complex technical issues to both technical and non-technical audiences\n• "Self-starter" attitude and ability to make decisions independently\n• Strong desire to learn and grow and a helpful, can-do attitude and a willingness to take ownership of problems\n• Experience with unit testing (TDD)\n\nResponsibilities\n• Gathering functional requirements, developing technical specifications, and project & test planning\n• Designing/developing prototypes, or proofs of concepts\n• Roughly 75-85% hands-on coding (including test)\n• Demonstrate end-to-end ownership and full cycle engineering mindset; responsible for integration, functional, unit and performance testing\n• Resolve defects/bugs during QA testing, pre-production, production, and post-release patches\n• Work cross-functionally with various Intuit teams or business units to drive forward results\n• Contribute to the design and architecture of the project\n• Work in an Agile Development environment\n• Develops a deep understanding of customer perspectives\n• Designs and implements solutions within the context of higher-level design, business, technology and user requirements and constraints\n• Understands how they fit into the overall business strategy, so they can support the organization\'s priorities. Continuously challenges effectiveness of internal processes, tools and systems, recommending changes, as appropriate', 'job_posted_at_timestamp': 1696318479, 'job_posted_at_datetime_utc': '2023-10-03T07:34:39.000Z', 'tag': 'se', 'skills': ['java', 'software design', 'software development', 'test-driven development', 'communication skills', 'problem-solving', 'agile development']}, {'employer_name': 'Radley James', 'job_employment_type': 'FULLTIME', 'job_title': 'Python Developer', 'job_apply_link': 'https://ca.bebee.com/job/20231003-62eea8cdfa0065d604353c32044b2398', 'job_description': 'We are a leading recruitment company, representing a forward-thinking Fintech firm that specialises in the design, development, and maintenance of cutting-edge algorithms for their trading clientele. They are actively seeking to recruit Python Developers for their Montreal team. The ideal candidates will possess a keen interest in working on mathematical/quant applications with the ambition to evolve into Quant Developers.\n\nThe role involves creating Python applications utilising Pandas and Numpy for tasks including data priming, model execution, and post-trade processes. This opportunity comes at an exciting time with several new product launches planned for the next 12-18 months.\n\nCandidate Requirements:\n• Possession of a Computer Science or related degree from a top-tier university.\n• 2-5 years of experience in developing quantitative, data-intensive products using Python, Pandas, and Numpy.\n• An interest in interfacing directly with businesses in a flat-structured environment, including traders and quants.\n\nComprehensive understanding of commercial development practices, encompassing testing, documentation, package management, and the Software Development Life Cycle (SDLC). The company offers a hybrid work model and a highly competitive compensation package. We welcome you to be part of this dynamic and innovative team.', 'job_posted_at_timestamp': 1696348697, 'job_posted_at_datetime_utc': '2023-10-03T15:58:17.000Z', 'tag': 'pd', 'skills': ['python', 'pandas', 'numpy', 'quant developers']}, {'employer_name': 'Radley James', 'job_employment_type': 'FULLTIME', 'job_title': 'Python Developer', 'job_apply_link': 'https://ca.bebee.com/job/20231003-62eea8cdfa0065d604353c32044b2398', 'job_description': 'We are a leading recruitment company, representing a forward-thinking Fintech firm that specialises in the design, development, and maintenance of cutting-edge algorithms for their trading clientele. They are actively seeking to recruit Python Developers for their Montreal team. The ideal candidates will possess a keen interest in working on mathematical/quant applications with the ambition to evolve into Quant Developers.\n\nThe role involves creating Python applications utilising Pandas and Numpy for tasks including data priming, model execution, and post-trade processes. This opportunity comes at an exciting time with several new product launches planned for the next 12-18 months.\n\nCandidate Requirements:\n• Possession of a Computer Science or related degree from a top-tier university.\n• 2-5 years of experience in developing quantitative, data-intensive products using Python, Pandas, and Numpy.\n• An interest in interfacing directly with businesses in a flat-structured environment, including traders and quants.\n\nComprehensive understanding of commercial development practices, encompassing testing, documentation, package management, and the Software Development Life Cycle (SDLC). The company offers a hybrid work model and a highly competitive compensation package. We welcome you to be part of this dynamic and innovative team.', 'job_posted_at_timestamp': 1696348697, 'job_posted_at_datetime_utc': '2023-10-03T15:58:17.000Z', 'tag': 'pd', 'skills': ['python', 'pandas', 'numpy', 'quant developers']}, {'employer_name': 'Block', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Engineer, Reporting Tools', 'job_apply_link': 'https://jobs.smartrecruiters.com/Square/743999934390153-data-engineer-reporting-tools', 'job_description': 'Company Description\n\nBlock is one company built from many blocks, all united by the same purpose of economic empowerment. The blocks that form our foundational teams — People, Finance, Counsel, Hardware, Information Security, Platform Infrastructure Engineering, and more — provide support and guidance at the corporate level. They work across business groups and around the globe, spanning time zones and disciplines to develop inclusive People policies, forecast finances, give legal counsel, safeguard systems, nurture new initiatives, and more. Every challenge creates possibilities, and we need different perspectives to see them all. Bring yours to Block.\n\nJob Description\n\nAs a Data Engineer, you will play a crucial role in implementing, improving, and maintaining reporting platforms and data pipelines across Block. This includes partnering and consulting with business and analytics teams to provide guidance and assistance in creating and streamlining Looker reports and underlying ETL pipelines. As part of the Automated Reporting Tools team, you’ll help develop and lead trainings and inservices to communicate best practices, and you’ll co-host office hours to provide direct assistance. Your expertise and enthusiasm will inspire people across Block to adopt reporting best practices and build innovative self-serve reporting solutions!\n\nYou will:\n• Partner with product analysts, data scientists, business users, and others to understand their needs and come up with an end-to-end solution\n• Translate business requirements to actionable data tasks (English <-> SQL)\n• Design and develop scalable turn-key ETL pipelines\n• Be self-driven in identifying gaps and root causes, designing and implementing solutions to stabilize and scale data solutions.\n• Monitor daily execution, diagnose and log issues, and fix pipelines to ensure SLAs are met with internal stakeholders.\n• Hold office hours, training sessions, brown bags and more to evangelize Looker and ETL best practices throughout the company\n\nQualifications\n\nRequired:\n• 2+ years working on a successful business intelligence team\n• Strong business intuition and ability to understand complex business systems\n• Strong technical accomplishments in SQL and data analysis skills\n• Expertise in visualization platforms including Looker, ThoughtSpot and/or another BI tool\n• Snowflake, Redshift, MySQL or similar data warehousing experience\n• Familiarity with structuring and writing ETLs\n\nPreferred:\n• Prior Airflow experience\n• Teaching/training/consulting experience\n• Work experience with with Python, Ruby or Javascript\n• Experience with Linux/OSX command line and git\n\nAdditional Information\n\nUS and Canada EEOC Statement\n\nWe’re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.\n\nWe believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible. Want to learn more about what we’re doing to build a workplace that is fair and square? Check out our I+D page.\n\nAdditionally, we consider qualified applicants with criminal histories for employment on our team, and always assess candidates on an individualized basis.\n\nPerks\n\nWe want you to be well and thrive. Our global benefits package includes:\n• Healthcare coverage\n• Retirement Plans\n• Employee Stock Purchase Program\n• Wellness perks\n• Paid parental leave\n• Paid time off\n• Learning and Development resources\n\nBlock, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.', 'job_posted_at_timestamp': 1696280058, 'job_posted_at_datetime_utc': '2023-10-02T20:54:18.000Z', 'tag': 'de', 'skills': ['sql', 'looker', 'etl', '***', 'python', 'ruby', 'javascript', 'linux', 'git']}, {'employer_name': 'Block', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Engineer, Reporting Tools', 'job_apply_link': 'https://jobs.smartrecruiters.com/Square/743999934390153-data-engineer-reporting-tools', 'job_description': 'Company Description\n\nBlock is one company built from many blocks, all united by the same purpose of economic empowerment. The blocks that form our foundational teams — People, Finance, Counsel, Hardware, Information Security, Platform Infrastructure Engineering, and more — provide support and guidance at the corporate level. They work across business groups and around the globe, spanning time zones and disciplines to develop inclusive People policies, forecast finances, give legal counsel, safeguard systems, nurture new initiatives, and more. Every challenge creates possibilities, and we need different perspectives to see them all. Bring yours to Block.\n\nJob Description\n\nAs a Data Engineer, you will play a crucial role in implementing, improving, and maintaining reporting platforms and data pipelines across Block. This includes partnering and consulting with business and analytics teams to provide guidance and assistance in creating and streamlining Looker reports and underlying ETL pipelines. As part of the Automated Reporting Tools team, you’ll help develop and lead trainings and inservices to communicate best practices, and you’ll co-host office hours to provide direct assistance. Your expertise and enthusiasm will inspire people across Block to adopt reporting best practices and build innovative self-serve reporting solutions!\n\nYou will:\n• Partner with product analysts, data scientists, business users, and others to understand their needs and come up with an end-to-end solution\n• Translate business requirements to actionable data tasks (English <-> SQL)\n• Design and develop scalable turn-key ETL pipelines\n• Be self-driven in identifying gaps and root causes, designing and implementing solutions to stabilize and scale data solutions.\n• Monitor daily execution, diagnose and log issues, and fix pipelines to ensure SLAs are met with internal stakeholders.\n• Hold office hours, training sessions, brown bags and more to evangelize Looker and ETL best practices throughout the company\n\nQualifications\n\nRequired:\n• 2+ years working on a successful business intelligence team\n• Strong business intuition and ability to understand complex business systems\n• Strong technical accomplishments in SQL and data analysis skills\n• Expertise in visualization platforms including Looker, ThoughtSpot and/or another BI tool\n• Snowflake, Redshift, MySQL or similar data warehousing experience\n• Familiarity with structuring and writing ETLs\n\nPreferred:\n• Prior Airflow experience\n• Teaching/training/consulting experience\n• Work experience with with Python, Ruby or Javascript\n• Experience with Linux/OSX command line and git\n\nAdditional Information\n\nUS and Canada EEOC Statement\n\nWe’re working to build a more inclusive economy where our customers have equal access to opportunity, and we strive to live by these same values in building our workplace. Block is a proud equal opportunity employer. We work hard to evaluate all employees and job applicants consistently, without regard to race, color, religion, gender, national origin, age, disability, pregnancy, gender expression or identity, sexual orientation, citizenship, or any other legally protected class.\n\nWe believe in being fair, and are committed to an inclusive interview experience, including providing reasonable accommodations to disabled applicants throughout the recruitment process. We encourage applicants to share any needed accommodations with their recruiter, who will treat these requests as confidentially as possible. Want to learn more about what we’re doing to build a workplace that is fair and square? Check out our I+D page.\n\nAdditionally, we consider qualified applicants with criminal histories for employment on our team, and always assess candidates on an individualized basis.\n\nPerks\n\nWe want you to be well and thrive. Our global benefits package includes:\n• Healthcare coverage\n• Retirement Plans\n• Employee Stock Purchase Program\n• Wellness perks\n• Paid parental leave\n• Paid time off\n• Learning and Development resources\n\nBlock, Inc. (NYSE: SQ) is a global technology company with a focus on financial services. Made up of Square, Cash App, Spiral, TIDAL, and TBD, we build tools to help more people access the economy. Square helps sellers run and grow their businesses with its integrated ecosystem of commerce solutions, business software, and banking services. With Cash App, anyone can easily send, spend, or invest their money in stocks or Bitcoin. Spiral (formerly Square Crypto) builds and funds free, open-source Bitcoin projects. Artists use TIDAL to help them succeed as entrepreneurs and connect more deeply with fans. TBD is building an open developer platform to make it easier to access Bitcoin and other blockchain technologies without having to go through an institution.', 'job_posted_at_timestamp': 1696280058, 'job_posted_at_datetime_utc': '2023-10-02T20:54:18.000Z', 'tag': 'de', 'skills': ['sql', 'looker', 'etl', '***', 'python', 'ruby', 'javascript', 'linux', 'git']}, {'employer_name': 'Olympic Industries ULC', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Engineer Intern/Co-op - January 2024', 'job_apply_link': 'https://en-ca.whatjobs.com/jobs/Data-Engineer-Intern-Co-op/british-columbia/66861841', 'job_description': "←Back to all jobs at Olympic Industries ULC\nData Engineer Intern/Co-op - January 2024\n• *\n• WhoWe Are\n\nOlympic Industries ULC is a leading international forest productstrading company with our annual revenue exceeding $500 million. Our expertise includes the trading, importing/exporting,and manufacturing of forest products from the comfort of our office located inthe heart of the vibrant and breathtaking Lonsdale Quay in North Vancouver, BC.\n\nEstablished in 1972, we have a strong record of success and aclear vision for our industry's sustainable future. With over 30 activeCommodity Traders in house, we are proud to have a corporate culture thatrewards hard work, entrepreneurship, and team collaboration.\n\nOpportunity\n\nOlympicIndustries ULC is currently searching for a highly motivated and innovative Data Engineer Intern to join our team from January through April 2024. Working alongside the Derivatives & DataTeam, the Data Engineer will gain hands-on experience in constructing andmaintaining data pipelines, optimizing infrastructure for scalability, andassisting on various AI and ML projects.\n\nResponsibilities\n\nReporting to the DerivativesData Engineer and Data Scientist , the Data Engineer/Developer is responsible for the followingas well as other related duties as assigned to support the business objectivesand purpose of the company:\n• Identify, design, and implement internalprocess improvements including re-designing infrastructure for greaterscalability, optimizing data delivery, and automating manual processes.\n• Develop and manage well-functioning databasesand applications.\n• Assist in code optimization in data scienceand trading projects.\n• Troubleshoot and debug automation andscraping program code.\n• Provide data analysis and data sourcingresponsibilities.\n• Assist in AI,ML projects.\n\nPositionRequirements\n\nTo be successful asa Data Engineer, an individual must be committed to developing, maintaining,and demonstrating the following:\nEducation andExperience\n• An academic background in Computer Science,Software/Computer Engineering, or a related technical field.\n• 1+ years of experiencein writing SQL queries and working with databases, such as MSSQL, MySQL,PostgreSQL, and MongoDB.\n• Strong programmingskills in Python.\n• Familiar with datamanipulation libraries such as Pandas, NumPy, Seaborn, and Matplotlib.\n• Workingknowledge of basic data structures and algorithms.\n• Knowledge/Experiencein Google Sheets and App Script.\n• Knowledge/Experiencein machine learning, data mining, statistical modeling, and forecasting.\n• Familiar withmachine learning and data mining libraries (e.g. TensorFlow, Scikit-learn,XGBoost).\n• Knowledge/Experiencein working with REST API and Web Socket to extract, manipulate, and automatedata considered an asset.\n• Knowledge/Experience in front-end development with React, Angular, HTML, and/or CSSconsidered an asset.\n• Knowledge/Experience in back-end web frameworks such asNode, Express, Django, and/or Flask considered an asset.\n\nCompetences\n• Proven ability to complete work in atimely manner with exceptional accuracy and attention to detail.\n• Outstanding verbal, written, andvisual communication skills.\n• A high degree of initiative, workethic, integrity, and honesty.\n• Ability to listen and understandinstructions and work independently or with others to complete tasks.\n• Working knowledge of MicrosoftOffice, including Outlook, Word, and Excel.\n• Ability to use strong judgment inanalyzing, troubleshooting, and evaluating problems.\n• Ability to act with good judgment anddiscretion: keeping sensitive business data secure.\n• Desire and capacity to acquire newknowledge and develop new skills, specifically in the commodities tradingindustry.\n• Abilityto conduct research into systems issues as required.\n• High-energy with an entrepreneurialspirit.\n\nCompensation\n• $60K-65K perannum.\n• Nespresso coffee& tea bar.\n• On-site gym &showers.\n\nWhy Join Us?\n\nSmall Company with Big Perks\n\nOlympic is a mid-sized company with anopen door/open concept layout where anybody you may need is easily accessible.This layout not only helps to support individuals in their career growth anddevelopment but also encourages individuals to interact and be curious abouthow different departments support each other in their roles.\nGreat Central Location\n\nLocated in the Lonsdale Quay, Olympic istransit accessible from any location in the lower mainland. There are manygreat shops, restaurants, and parks within a walking distance and the mountainsare just a 10-minute drive away.\n\nFor moreinformation on Olympic Industries, please visit our website at .\n\nWe thank allapplicants for their interest! However, only those selected for an interviewwill be contacted. At Olympic Industries, we embrace diversity and arecommitted to building a team that represents a variety of backgrounds,cultures, perspectives skills, and experiences. As an equal opportunityemployer, we encourage applications from all qualified individuals.\n\nPlease visit our careers page to see more job opportunities.", 'job_posted_at_timestamp': 1696291200, 'job_posted_at_datetime_utc': '2023-10-03T00:00:00.000Z', 'tag': 'de', 'skills': ['sql queries', 'python programming', 'data manipulation', 'structures algorithms', 'google sheets', 'machine learning', 'rest api', 'front-end development', 'web development']}, {'employer_name': 'Olympic Industries ULC', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Engineer Intern/Co-op - January 2024', 'job_apply_link': 'https://en-ca.whatjobs.com/jobs/Data-Engineer-Intern-Co-op/british-columbia/66861841', 'job_description': "←Back to all jobs at Olympic Industries ULC\nData Engineer Intern/Co-op - January 2024\n• *\n• WhoWe Are\n\nOlympic Industries ULC is a leading international forest productstrading company with our annual revenue exceeding $500 million. Our expertise includes the trading, importing/exporting,and manufacturing of forest products from the comfort of our office located inthe heart of the vibrant and breathtaking Lonsdale Quay in North Vancouver, BC.\n\nEstablished in 1972, we have a strong record of success and aclear vision for our industry's sustainable future. With over 30 activeCommodity Traders in house, we are proud to have a corporate culture thatrewards hard work, entrepreneurship, and team collaboration.\n\nOpportunity\n\nOlympicIndustries ULC is currently searching for a highly motivated and innovative Data Engineer Intern to join our team from January through April 2024. Working alongside the Derivatives & DataTeam, the Data Engineer will gain hands-on experience in constructing andmaintaining data pipelines, optimizing infrastructure for scalability, andassisting on various AI and ML projects.\n\nResponsibilities\n\nReporting to the DerivativesData Engineer and Data Scientist , the Data Engineer/Developer is responsible for the followingas well as other related duties as assigned to support the business objectivesand purpose of the company:\n• Identify, design, and implement internalprocess improvements including re-designing infrastructure for greaterscalability, optimizing data delivery, and automating manual processes.\n• Develop and manage well-functioning databasesand applications.\n• Assist in code optimization in data scienceand trading projects.\n• Troubleshoot and debug automation andscraping program code.\n• Provide data analysis and data sourcingresponsibilities.\n• Assist in AI,ML projects.\n\nPositionRequirements\n\nTo be successful asa Data Engineer, an individual must be committed to developing, maintaining,and demonstrating the following:\nEducation andExperience\n• An academic background in Computer Science,Software/Computer Engineering, or a related technical field.\n• 1+ years of experiencein writing SQL queries and working with databases, such as MSSQL, MySQL,PostgreSQL, and MongoDB.\n• Strong programmingskills in Python.\n• Familiar with datamanipulation libraries such as Pandas, NumPy, Seaborn, and Matplotlib.\n• Workingknowledge of basic data structures and algorithms.\n• Knowledge/Experiencein Google Sheets and App Script.\n• Knowledge/Experiencein machine learning, data mining, statistical modeling, and forecasting.\n• Familiar withmachine learning and data mining libraries (e.g. TensorFlow, Scikit-learn,XGBoost).\n• Knowledge/Experiencein working with REST API and Web Socket to extract, manipulate, and automatedata considered an asset.\n• Knowledge/Experience in front-end development with React, Angular, HTML, and/or CSSconsidered an asset.\n• Knowledge/Experience in back-end web frameworks such asNode, Express, Django, and/or Flask considered an asset.\n\nCompetences\n• Proven ability to complete work in atimely manner with exceptional accuracy and attention to detail.\n• Outstanding verbal, written, andvisual communication skills.\n• A high degree of initiative, workethic, integrity, and honesty.\n• Ability to listen and understandinstructions and work independently or with others to complete tasks.\n• Working knowledge of MicrosoftOffice, including Outlook, Word, and Excel.\n• Ability to use strong judgment inanalyzing, troubleshooting, and evaluating problems.\n• Ability to act with good judgment anddiscretion: keeping sensitive business data secure.\n• Desire and capacity to acquire newknowledge and develop new skills, specifically in the commodities tradingindustry.\n• Abilityto conduct research into systems issues as required.\n• High-energy with an entrepreneurialspirit.\n\nCompensation\n• $60K-65K perannum.\n• Nespresso coffee& tea bar.\n• On-site gym &showers.\n\nWhy Join Us?\n\nSmall Company with Big Perks\n\nOlympic is a mid-sized company with anopen door/open concept layout where anybody you may need is easily accessible.This layout not only helps to support individuals in their career growth anddevelopment but also encourages individuals to interact and be curious abouthow different departments support each other in their roles.\nGreat Central Location\n\nLocated in the Lonsdale Quay, Olympic istransit accessible from any location in the lower mainland. There are manygreat shops, restaurants, and parks within a walking distance and the mountainsare just a 10-minute drive away.\n\nFor moreinformation on Olympic Industries, please visit our website at .\n\nWe thank allapplicants for their interest! However, only those selected for an interviewwill be contacted. At Olympic Industries, we embrace diversity and arecommitted to building a team that represents a variety of backgrounds,cultures, perspectives skills, and experiences. As an equal opportunityemployer, we encourage applications from all qualified individuals.\n\nPlease visit our careers page to see more job opportunities.", 'job_posted_at_timestamp': 1696291200, 'job_posted_at_datetime_utc': '2023-10-03T00:00:00.000Z', 'tag': 'de', 'skills': ['sql queries', 'python programming', 'data manipulation', 'structures algorithms', 'google sheets', 'machine learning', 'rest api', 'front-end development', 'web development']}, {'employer_name': 'Altis Technology', 'job_employment_type': 'CONTRACTOR', 'job_title': 'Entry Level Data Analyst', 'job_apply_link': 'https://ca.bebee.com/job/20231003-67580fd33698d803365a94d67fc68e86', 'job_description': "Company Profile\n\nAltis Technology Recruitment is one of Canada's largest independent recruitment firms dedicated to placing I.T. professionals in contract and permanent roles.\n\nWe represent specialized talent in a variety of disciplines, including Database and Business Intelligence, I.T. Project and Business Management, Application Development, and Network and Systems Infrastructure.\n\nOur goal is to introduce the best technical resources to the right employers.\n\nJunior / Entry Level Data Analyst - Remote\n\nAre you looking for your next challenging and rewarding opportunity? Then this is the position for you\n\nYou will be a point of contact to troubleshoot issues for our end user community and work beyond tactical support to analyze issues and identify opportunities for process improvements.\n\nResponsibilities :\n\n70% - Data Analysis - pulling data, identifying missing data, following up with supplier to get data completed\n\n30% - Process Improvement - create process improvements for solutions from data analysis\n\nThis is a great opportunity to be part of a larger organization that believes in promoting talent from within. This is an exciting role that will definitely advance your career This is a 6-12 month contract opportunity with potential to extend or convert to direct hire.\n\nThis role will be working remotely and you must be able to work eastern standard time zone.\n\nRequired Skills :\n\n1+ years of analysis experience\n\nProven Process analysis and improvement - given incomplete work and took ownership to figure out a solution\n\nStrong Excel skills - ability to create Pivot tables, V-LookUps, Charts, Graphs, Formulas\n\nBasic SQL Experience - write, pull, and modify queries from a database (Access or SQL Server or similar database)\n\nPowerpoint experience\n\nExperience drawing conclusions from data\n\nOutstanding written and verbal communication skills\n\nEffective interpersonal and problem solving skills - driver mentality\n\nAbility to handle and prioritize multiple tasks\n\nBachelor's degree in I.E or Supply Chain or related field\n\nPreferred Skills :\n\nKnowledge of word processing tools and spreadsheets (MS Office Word, Excel etc.)\n\nWorking knowledge of office equipment\n\nBasic understanding of databases\n\nImportant : You Will Receive An Email Within Next 24 hours, Check Your Inbox or Spam Folder For next steps.\n\nPowered by Webbtree\n\n1 day ago", 'job_posted_at_timestamp': 1696319513, 'job_posted_at_datetime_utc': '2023-10-03T07:51:53.000Z', 'tag': 'da', 'skills': ['analysis experience', 'process improvement', 'excel skills', 'sql experience', 'powerpoint experience', 'effective communication', 'interpersonal problem-solving', 'multitasking, prioritization', "bachelor's degree", 'word processing', 'office equipment', 'database comprehension']}, {'employer_name': 'Altis Technology', 'job_employment_type': 'CONTRACTOR', 'job_title': 'Entry Level Data Analyst', 'job_apply_link': 'https://ca.bebee.com/job/20231003-67580fd33698d803365a94d67fc68e86', 'job_description': "Company Profile\n\nAltis Technology Recruitment is one of Canada's largest independent recruitment firms dedicated to placing I.T. professionals in contract and permanent roles.\n\nWe represent specialized talent in a variety of disciplines, including Database and Business Intelligence, I.T. Project and Business Management, Application Development, and Network and Systems Infrastructure.\n\nOur goal is to introduce the best technical resources to the right employers.\n\nJunior / Entry Level Data Analyst - Remote\n\nAre you looking for your next challenging and rewarding opportunity? Then this is the position for you\n\nYou will be a point of contact to troubleshoot issues for our end user community and work beyond tactical support to analyze issues and identify opportunities for process improvements.\n\nResponsibilities :\n\n70% - Data Analysis - pulling data, identifying missing data, following up with supplier to get data completed\n\n30% - Process Improvement - create process improvements for solutions from data analysis\n\nThis is a great opportunity to be part of a larger organization that believes in promoting talent from within. This is an exciting role that will definitely advance your career This is a 6-12 month contract opportunity with potential to extend or convert to direct hire.\n\nThis role will be working remotely and you must be able to work eastern standard time zone.\n\nRequired Skills :\n\n1+ years of analysis experience\n\nProven Process analysis and improvement - given incomplete work and took ownership to figure out a solution\n\nStrong Excel skills - ability to create Pivot tables, V-LookUps, Charts, Graphs, Formulas\n\nBasic SQL Experience - write, pull, and modify queries from a database (Access or SQL Server or similar database)\n\nPowerpoint experience\n\nExperience drawing conclusions from data\n\nOutstanding written and verbal communication skills\n\nEffective interpersonal and problem solving skills - driver mentality\n\nAbility to handle and prioritize multiple tasks\n\nBachelor's degree in I.E or Supply Chain or related field\n\nPreferred Skills :\n\nKnowledge of word processing tools and spreadsheets (MS Office Word, Excel etc.)\n\nWorking knowledge of office equipment\n\nBasic understanding of databases\n\nImportant : You Will Receive An Email Within Next 24 hours, Check Your Inbox or Spam Folder For next steps.\n\nPowered by Webbtree\n\n1 day ago", 'job_posted_at_timestamp': 1696319513, 'job_posted_at_datetime_utc': '2023-10-03T07:51:53.000Z', 'tag': 'da', 'skills': ['analysis experience', 'process improvement', 'excel skills', 'sql experience', 'powerpoint experience', 'effective communication', 'interpersonal problem-solving', 'multitasking, prioritization', "bachelor's degree", 'word processing', 'office equipment', 'database comprehension']}, {'employer_name': 'Flighthub', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Analyst', 'job_apply_link': 'https://ca.trabajo.org/job-850-20231003-52a7e49cfaee5b12453bfee9bd416708', 'job_description': 'We are looking for a Data Analyst, with 1-2 years of experience to join our team. Working alongside Roman, Sr Director, Content Integration, you will be responsible for analyzing our operational performance metrics, specifically related to our new content integrations. Play a key role in gathering data related to our deployments while helping build out our operational workflows. Our teams will count on you to compile and extract data from various sources to identify issues and provide insights on changes.\n\nMany career paths can prepare you for this life-changing opportunity, but preferably, you’re highly skilled in:\nUsing Excel to compile reports and perform calculations; Working with SQL to support data analysis; Working with modern web browsers & tools; Performing root-cause analysis to identify and resolve issues; Analyzing large sets of data; Working in a fast-paced and technological environment;', 'job_posted_at_timestamp': 1696300778, 'job_posted_at_datetime_utc': '2023-10-03T02:39:38.000Z', 'tag': 'da', 'skills': ['excel', 'sql', 'root-cause analysis', 'data analysis']}, {'employer_name': 'Flighthub', 'job_employment_type': 'FULLTIME', 'job_title': 'Data Analyst', 'job_apply_link': 'https://ca.trabajo.org/job-850-20231003-52a7e49cfaee5b12453bfee9bd416708', 'job_description': 'We are looking for a Data Analyst, with 1-2 years of experience to join our team. Working alongside Roman, Sr Director, Content Integration, you will be responsible for analyzing our operational performance metrics, specifically related to our new content integrations. Play a key role in gathering data related to our deployments while helping build out our operational workflows. Our teams will count on you to compile and extract data from various sources to identify issues and provide insights on changes.\n\nMany career paths can prepare you for this life-changing opportunity, but preferably, you’re highly skilled in:\nUsing Excel to compile reports and perform calculations; Working with SQL to support data analysis; Working with modern web browsers & tools; Performing root-cause analysis to identify and resolve issues; Analyzing large sets of data; Working in a fast-paced and technological environment;', 'job_posted_at_timestamp': 1696300778, 'job_posted_at_datetime_utc': '2023-10-03T02:39:38.000Z', 'tag': 'da', 'skills': ['excel', 'sql', 'root-cause analysis', 'data analysis']}]
[2023-10-03T19:32:56.262+0000] {database.py:12} WARNING - Cluster.__init__ called with contact_points specified, but no load_balancing_policy. In the next major version, this will raise an error; please specify a load-balancing policy. (contact_points = ['cassandra_db'], lbp = None)
[2023-10-03T19:32:56.311+0000] {database.py:13} WARNING - Downgrading core protocol version from 66 to 65 for 172.24.0.3:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-10-03T19:32:56.315+0000] {database.py:13} WARNING - Downgrading core protocol version from 65 to 5 for 172.24.0.3:9042. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version
[2023-10-03T19:32:56.377+0000] {policies.py:289} INFO - Using datacenter 'datacenter1' for DCAwareRoundRobinPolicy (via host '172.24.0.3:9042'); if incorrect, please specify a local_dc to the constructor, or limit contact points to local cluster nodes
[2023-10-03T19:32:56.468+0000] {logging_mixin.py:149} INFO - Created Keyspace
[2023-10-03T19:32:56.760+0000] {logging_mixin.py:149} INFO - Created Schema
[2023-10-03T19:32:56.761+0000] {logging_mixin.py:149} INFO - Database creation DONE
[2023-10-03T19:32:56.762+0000] {logging_mixin.py:149} INFO - TAAAAG ml
[2023-10-03T19:32:56.775+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.777+0000] {logging_mixin.py:149} INFO - TAAAAG ml
[2023-10-03T19:32:56.785+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.787+0000] {logging_mixin.py:149} INFO - TAAAAG ml
[2023-10-03T19:32:56.794+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.795+0000] {logging_mixin.py:149} INFO - TAAAAG ml
[2023-10-03T19:32:56.802+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.806+0000] {logging_mixin.py:149} INFO - TAAAAG ds
[2023-10-03T19:32:56.813+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.815+0000] {logging_mixin.py:149} INFO - TAAAAG ds
[2023-10-03T19:32:56.823+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.824+0000] {logging_mixin.py:149} INFO - TAAAAG ds
[2023-10-03T19:32:56.832+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.833+0000] {logging_mixin.py:149} INFO - TAAAAG ds
[2023-10-03T19:32:56.839+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.841+0000] {logging_mixin.py:149} INFO - TAAAAG se
[2023-10-03T19:32:56.847+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.848+0000] {logging_mixin.py:149} INFO - TAAAAG se
[2023-10-03T19:32:56.854+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.855+0000] {logging_mixin.py:149} INFO - TAAAAG se
[2023-10-03T19:32:56.860+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.862+0000] {logging_mixin.py:149} INFO - TAAAAG se
[2023-10-03T19:32:56.866+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.869+0000] {logging_mixin.py:149} INFO - TAAAAG pd
[2023-10-03T19:32:56.874+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.876+0000] {logging_mixin.py:149} INFO - TAAAAG pd
[2023-10-03T19:32:56.882+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.886+0000] {logging_mixin.py:149} INFO - TAAAAG de
[2023-10-03T19:32:56.898+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.900+0000] {logging_mixin.py:149} INFO - TAAAAG de
[2023-10-03T19:32:56.906+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.907+0000] {logging_mixin.py:149} INFO - TAAAAG de
[2023-10-03T19:32:56.913+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.915+0000] {logging_mixin.py:149} INFO - TAAAAG de
[2023-10-03T19:32:56.922+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.924+0000] {logging_mixin.py:149} INFO - TAAAAG da
[2023-10-03T19:32:56.931+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.933+0000] {logging_mixin.py:149} INFO - TAAAAG da
[2023-10-03T19:32:56.938+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.940+0000] {logging_mixin.py:149} INFO - TAAAAG da
[2023-10-03T19:32:56.945+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.946+0000] {logging_mixin.py:149} INFO - TAAAAG da
[2023-10-03T19:32:56.951+0000] {logging_mixin.py:149} INFO - Inserted data
[2023-10-03T19:32:56.952+0000] {python.py:183} INFO - Done. Returned value was: None
[2023-10-03T19:32:56.967+0000] {taskinstance.py:1368} INFO - Marking task as SUCCESS. dag_id=job_extraction_with_task_flow, task_id=insert_into_database, execution_date=20231003T193003, start_date=20231003T193256, end_date=20231003T193256
[2023-10-03T19:32:57.003+0000] {local_task_job_runner.py:232} INFO - Task exited with return code 0
[2023-10-03T19:32:57.020+0000] {taskinstance.py:2674} INFO - 0 downstream tasks scheduled from follow-on schedule check
